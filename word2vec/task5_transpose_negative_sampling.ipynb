{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "task5_transpose_negative_sampling.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "waheQ4kPJ64M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Negative sampling\n",
        "\n",
        "You may have noticed that word2vec is really slow to train. Especially with big (> 50 000) vocabularies. Negative sampling is the solution.\n",
        "\n",
        "The task is to implement word2vec with negative sampling. In more detail: you should implement two ways of negative sampling.\n",
        "\n",
        "## Vanilla negative sampling\n",
        "\n",
        "This is what was discussed in Stanford lecture. The main idea is in the formula:\n",
        "\n",
        "$$ L = \\log\\sigma(u^T_o u_c) + \\sum^k_{i=1} \\mathbb{E}_{j \\sim P(w)}[\\log\\sigma(-u^T_j, u_c)]$$\n",
        "\n",
        "Where $\\sigma$ - sigmoid function, $u_c$ - central word vector, $u_o$ - context (outside of the window) word vector, $u_j$ - vector or word with index $j$.\n",
        "\n",
        "The first term calculates the similarity between positive examples (word from one window)\n",
        "\n",
        "The second term is responsible for negative samples. $k$ is a hyperparameter - the number of negatives to sample.\n",
        "$\\mathbb{E}_{j \\sim P(w)}$\n",
        "means that $j$ is distributed accordingly to unigram distribution, but it is better to use $P^{3/4}(w)$ (empirical results) and you can experiment with some other approaches (for example, try to use uniform distribution).\n",
        "\n",
        "Thus, it is only required to calculate the similarity between positive samples and some other negatives. Not across all the vocabulary.\n",
        "\n",
        "Useful links:\n",
        "1. [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/pdf/1301.3781.pdf)\n",
        "1. [Distributed Representations of Words and Phrases and their Compositionality](http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)\n",
        "\n",
        "## Batch-transpose trick for negative sampling\n",
        "\n",
        "But we can do better. Maybe we don't need to compute vectors for negative samples at all, because we already have a batch of training data and (hopefully) examples in the batch are highly decorrelated.\n",
        "\n",
        "Let's assume we work with Skip-gram model.\n",
        "\n",
        "Let $S$ be a batch of _L2-normalized_ word vectors `(batch_size, 2*window_size + 1, word_vector_dim)`.\n",
        "\n",
        "```python\n",
        "x = 0.0\n",
        "for batch_idx in range(batch):\n",
        "    w = S[batch_idx, :, :]\n",
        "    x += np.sum(w.T @ w - 1.)\n",
        "\n",
        "y = 0.0\n",
        "for window_idx in range(window):\n",
        "    b = S[:, window_idx, :]\n",
        "    y += np.sum(b.T @ b)\n",
        "\n",
        "loss = -x + y```\n",
        "\n",
        "Think about this loss and compare it to vanilla negative sampling.\n",
        "\n",
        "Implement word2vec with batch-transpose trick. Modify the formula, if needed.\n",
        "\n",
        "If you are interested: [more info](https://www.tensorflow.org/extras/candidate_sampling.pdf) on other methods of candidate sampling.\n",
        "\n",
        "**Results of this task** are the very same as in task 3, **plus**:\n",
        " * implement two models (one with vanilla negative sampling and the other with batch-transpose trick)\n",
        " * compare all of the models from tasks 3-5. In terms of time and number of iterations until convergence and the quality of the resulting vectors.\n",
        " * answer the questions\n",
        " ### Results:\n",
        " * Done, the second model is in the same zip file\n",
        " * The model from the 3 task were giving the best results, and after 2 hours of training get stable (7 epochs), the same is for 4th model, but in this case the nearst neighbours were not that good, but the analogies were perfect. In the 5 models, we get a super fast training process, about 8 hours for (52 epochs), but the vectors were not that good for vanila, it seems that in nearest neighbours it is just random sets of words. But in batch_transpose model we achived good results, which show the semantic structure.\n",
        "\n",
        "### Questions:\n",
        "1. Explain the batch-transpose trick formula in your own words. How would you name x, y, w and b?\n",
        "1. Should it be modified to serve as a word2vec loss? If yes, how?\n",
        "1. Is it possible to do the same trick with CBOW model? If yes, how?\n",
        "1. Does it matter how the batch is made in the case of batch-transpose trick? In the case of vanilla negative sampling?\n",
        "### Answers:\n",
        "1. I would name them to_maximize, to_minimize, dot_products_to_positive, dot_product_to_negative respectively, since by taking w.T @ w - 1. and summing up we are just summing the dot products of the words in one 2 * window_size + 1 window. We need to maximize this, and then we subtract the dot_products of i-th words in different windows, since we suggest that they are highly decorellated.\n",
        "2. Firstly, we have to swap w.T and w, since we have to multiply embeddings.\n",
        "    Secondly, dot product is beetwen 1 and -1, therefore by taking log_sigmoid we will maximize the overall probability (log(a * b) = log(a) + log(b)). Or we just add 1. and dividing by 2. in order to maximize cosine similarity, and this is equivalent to what is written in the formulae.\n",
        "3. No, since here we predicting (word, word) pairs, not (context, word) pairs\n",
        "4. Yes, we have to sample windows from different places of the text, in order to get decorellated pairs for the negative sampling. No in case of vanila model, there is no matter, we just have to itareto over all dataset (the negative samples are already known)\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "qoYSQU42J64O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"my implemenatation of word2vec embedding model with only one matrix of embeddings: https://arxiv.org/pdf/1411.2738.pdf\"\"\"\n",
        "import tensorflow as tf\n",
        "from tensorflow.train import AdamOptimizer\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "from tensorboardcolab import *\n",
        "from operator import itemgetter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lf5FZqaTKxK1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"batcher class for the model\"\"\"\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import Counter\n",
        "\n",
        "unknown_token = \"UNK\"\n",
        "\n",
        "class SkipGramBatcher:\n",
        "    def __init__(self, window_size=5, least_freq=3):\n",
        "        self.least_freq = least_freq\n",
        "        self.text = None\n",
        "        self.vocab = None\n",
        "        self.vocab_size = None\n",
        "        self.word2index = None\n",
        "        self.index2word = None\n",
        "        self.window_size = window_size\n",
        "        self.current_index = 0\n",
        "        self.current_diff = -window_size\n",
        "        self.total_size = 0\n",
        "    \n",
        "    def preprocess(self, text):\n",
        "        \"\"\"replace words with frequency < least_freq with unknown_token\n",
        "        and save the text\n",
        "        \"\"\"\n",
        "        counter = Counter(text)\n",
        "        def get_token(word):\n",
        "            if counter[word] < self.least_freq:\n",
        "                return unknown_token\n",
        "            else:\n",
        "                return word.lower()\n",
        "        self.text = [get_token(word) for word in text]\n",
        "    \n",
        "    def fit_text(self, text):\n",
        "        \"\"\"init text, vocab, word2ind, ind2word\n",
        "        \"\"\"\n",
        "        self.preprocess(text)\n",
        "        self.vocab = np.unique(self.text)\n",
        "        self.vocab_size = self.vocab.shape[0]\n",
        "        self.word2index = dict(zip(self.vocab, range(self.vocab.shape[0])))\n",
        "        self.index2word = dict(zip(range(self.vocab.shape[0]), self.vocab))\n",
        "        self.total_size = (len(self.text) - 3 * self.window_size) * self.window_size * 2\n",
        "        \n",
        "    def most_frequent(self, num=25):\n",
        "        \"\"\"get most frequent words from the text\"\"\"\n",
        "        counter = Counter(self.text)\n",
        "        return counter.most_common(num)\n",
        "        \n",
        "    def least_frequent(self, num=25):\n",
        "        \"\"\"get least frequent words from the text\"\"\"\n",
        "        counter = Counter(self.text)\n",
        "        return counter.most_common()[:-num - 1:-1]\n",
        "        \n",
        "    def indices_to_words(self, x_batch):\n",
        "        \"\"\"return array of words out of array of indices\"\"\"\n",
        "        return np.array([self.index2word[index] for index in x_batch])\n",
        "    \n",
        "    def words_to_indices(self, words):\n",
        "        \"\"\"return array of indices out of array of words\"\"\"\n",
        "        return np.array([self.word2index[word] for word in words])\n",
        "    \n",
        "    def _get_next_index_and_diff(self, current_index, current_diff):\n",
        "        if (current_diff == self.window_size):\n",
        "            current_diff = -self.window_size\n",
        "            current_index += 1\n",
        "            current_index %= len(self.text)\n",
        "        else:\n",
        "            if current_diff == -1:\n",
        "                current_diff = 1\n",
        "            else:\n",
        "                current_diff += 1\n",
        "        return current_index, current_diff\n",
        "\n",
        "    \n",
        "    def get_batch(self, batch_size=100):\n",
        "        \"\"\"return batch of indices for x and for labels consequently\"\"\"\n",
        "        x_batch = []\n",
        "        labels_batch = []\n",
        "        while len(x_batch) < batch_size:\n",
        "            label_index_in_text = self.current_index + self.current_diff \n",
        "            if (label_index_in_text < 0 or label_index_in_text >= len(self.text)):\n",
        "                index, diff = self._get_next_index_and_diff(self.current_index, self.current_diff)\n",
        "                self.current_index = index\n",
        "                self.current_diff = diff\n",
        "                continue\n",
        "                \n",
        "            word = self.text[self.current_index]\n",
        "            word_index = self.word2index[word]\n",
        "            label = self.text[self.current_index + self.current_diff]\n",
        "            label_index = self.word2index[label]\n",
        "            \n",
        "            x_batch.append(word_index)\n",
        "            labels_batch.append(label_index)\n",
        "            \n",
        "            index, diff = self._get_next_index_and_diff(self.current_index, self.current_diff)\n",
        "            self.current_index = index\n",
        "            self.current_diff = diff\n",
        "            \n",
        "        assert len(x_batch) == batch_size\n",
        "        assert len(labels_batch) == batch_size\n",
        "        \n",
        "        x_batch = np.array(x_batch)\n",
        "        labels_batch = np.array(labels_batch)\n",
        "        \n",
        "        permut = np.random.permutation(range(batch_size))\n",
        "        x_batch = x_batch[permut]\n",
        "        labels_batch = labels_batch[permut]\n",
        "        return x_batch, labels_batch\n",
        "      \n",
        "    def get_random_batch(self, batch_size=100):\n",
        "        \"\"\"return batch of bath_size index arrays of 2 * window_size + 1 words randomly\"\"\"\n",
        "        batch = []\n",
        "        \n",
        "        center_indices = np.random.choice(np.arange(self.window_size + 100, len(self.text) - self.window_size - 100), batch_size, replace=False)\n",
        "        indices = [ range(ind - self.window_size, ind + self.window_size + 1) for ind in center_indices]\n",
        "        words = [itemgetter(*row)(self.text) for row in indices] \n",
        "        batch = [np.array([self.word2index[word] for word in row]) for row in words]\n",
        "        \n",
        "        batch = np.array(batch)\n",
        "        return batch\n",
        "        \n",
        "    def batch_generator(self, batch_size=100):\n",
        "        \"\"\"generator for batch\"\"\"\n",
        "        while True:\n",
        "            x_batch, labels_batch = self.get_batch(batch_size)\n",
        "            yield x_batch, labels_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BYkREVcqK84g",
        "colab_type": "code",
        "outputId": "2b71c8ea-c47d-4999-84cb-03d361479ae5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\"preparing data for training, the data is text8 - preprocessed text with 17005208 words\"\"\"\n",
        "!mkdir logs\n",
        "!ls\n",
        "!wget http://mattmahoney.net/dc/text8.zip\n",
        "\n",
        "!ls\n",
        "!unzip text8.zip\n",
        "\n",
        "filename = 'text8' #file with the raw text\n",
        "text = []\n",
        "with open('text8', mode='r') as file:\n",
        "    line = file.readline()\n",
        "    while line:\n",
        "        text += line.lower().split(' ')\n",
        "        line = file.readline()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "logs  sample_data\n",
            "--2019-03-10 11:18:17--  http://mattmahoney.net/dc/text8.zip\n",
            "Resolving mattmahoney.net (mattmahoney.net)... 67.195.197.75\n",
            "Connecting to mattmahoney.net (mattmahoney.net)|67.195.197.75|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 31344016 (30M) [application/zip]\n",
            "Saving to: ‘text8.zip’\n",
            "\n",
            "text8.zip           100%[===================>]  29.89M   734KB/s    in 43s     \n",
            "\n",
            "2019-03-10 11:19:00 (720 KB/s) - ‘text8.zip’ saved [31344016/31344016]\n",
            "\n",
            "logs  sample_data  text8.zip\n",
            "Archive:  text8.zip\n",
            "  inflating: text8                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JMchWHqpK79_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"initializing batcher for the model\"\"\"\n",
        "batcher = SkipGramBatcher(window_size=3, least_freq=4)\n",
        "batcher.fit_text(text[:1000000])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2zkzyifGK9v9",
        "colab_type": "code",
        "outputId": "4f129494-457e-4a27-cccf-826c78934363",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\"gpu usage\"\"\"\n",
        "USE_GPU = True\n",
        "if USE_GPU:\n",
        "    device = '/device:GPU:0'\n",
        "else:\n",
        "    device = '/cpu:0'\n",
        "    \n",
        "print('Using device: ', device)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using device:  /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QxdQG-_vK-AO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"function for weights initialization\"\"\"\n",
        "def kaiming_normal(shape):\n",
        "    return tf.random_normal(shape) * np.sqrt(2.0 / shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1uZ1cOrwK-Qp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"logging parameters\"\"\"\n",
        "save_every = 200\n",
        "loss_every = 100\n",
        "summary_every = 200\n",
        "log_every = 75\n",
        "USE_TENSORBOARDCOLAB = False\n",
        "model_name = 'batch_transpose_'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZxcsiAO_K-jC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"word2vec class\"\"\"\n",
        "class Word2Vec:\n",
        "    def __init__(self, vocab_size, embeddings_size, window_size):\n",
        "        tf.reset_default_graph()\n",
        "        self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True))\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embeddings_size = embeddings_size\n",
        "        self.window_size = window_size\n",
        "        \n",
        "    def close(self):\n",
        "        tf.reset_default_graph()\n",
        "        self.sess.close()\n",
        "        \n",
        "    def init_weights(self):\n",
        "        self.w1 = tf.Variable(kaiming_normal((self.vocab_size, self.embeddings_size)), name='w1') \n",
        "        \n",
        "    def multiply_tensors(self, x, w):\n",
        "        n = tf.reshape(x, [-1, x.shape[2]])\n",
        "        h = tf.matmul(n, w)\n",
        "        return tf.reshape(h, [-1, x.shape[1], w.shape[1]])\n",
        "\n",
        "    def model_fn(self, x):\n",
        "        x = self.multiply_tensors(x, self.w1)\n",
        "        x = tf.math.l2_normalize(x, axis=2)\n",
        "        return x\n",
        "    \n",
        "    def get_loss(self, scores):\n",
        "        pos_dot_products = tf.matmul(scores, scores, transpose_b=True)\n",
        "        pos_dot_products = tf.math.subtract(pos_dot_products, tf.ones_like(pos_dot_products))\n",
        "        scores = tf.transpose(scores, perm=[1, 0, 2])\n",
        "        neg_dot_products = tf.matmul(scores, scores, transpose_b=True)\n",
        "        loss = -tf.reduce_sum(pos_dot_products) + tf.reduce_sum(neg_dot_products)\n",
        "        return loss\n",
        "    \n",
        "    def train(self, batcher, batch_size=10, epochs=3, learning_rate=0.01):        \n",
        "        with tf.device(device):\n",
        "            self.init_weights()\n",
        "            \n",
        "            x = tf.placeholder(dtype=tf.int32, shape=(batch_size, 2 * self.window_size + 1))           \n",
        "            \n",
        "            x_one_hot = tf.one_hot(x, self.vocab_size, axis=-1)\n",
        "            \n",
        "            scores = self.model_fn(x_one_hot)\n",
        "            loss = self.get_loss(scores)\n",
        "            tf.summary.scalar('cross_entropy', loss)\n",
        "            \n",
        "            train_op = AdamOptimizer(learning_rate).minimize(loss)\n",
        "            \n",
        "            saver = tf.train.Saver({\"w1\" : self.w1})\n",
        "            merged = tf.summary.merge_all()\n",
        "            \n",
        "            if USE_TENSORBOARDCOLAB:\n",
        "                tbc = TensorBoardColab()\n",
        "                train_writer = tbc.get_writer()\n",
        "                print()\n",
        "                print('initialized writer for tensorboard logging...')\n",
        "                print()\n",
        "            else:\n",
        "                train_writer = tf.summary.FileWriter('./tensorboard/train')\n",
        "            \n",
        "            #training\n",
        "            self.sess.run(tf.global_variables_initializer())\n",
        "            \n",
        "            min_loss = 1e9\n",
        "            losses = []\n",
        "            epoch_losses = []\n",
        "            print('Starting training...')\n",
        "            try:\n",
        "                for epoch in range(epochs):\n",
        "                    epoch_loss = 0\n",
        "                    iter_count = int(batcher.total_size / batch_size)\n",
        "                    for step in range(iter_count):\n",
        "                        batch = batcher.get_random_batch(batch_size)\n",
        "                        feed_dict = {x : batch}\n",
        "                        \n",
        "                        if step % summary_every == 0:\n",
        "                            print('writing summary to tensorboard...')\n",
        "                            print()\n",
        "                            summary = self.sess.run(merged, feed_dict=feed_dict)\n",
        "                            train_writer.add_summary(summary, iter_count * epoch + step)\n",
        "                        \n",
        "                        np_loss, _ = self.sess.run([loss, train_op], feed_dict=feed_dict)\n",
        "                        epoch_loss += np_loss \n",
        "                        average_loss = epoch_loss / (step + 1)\n",
        "                        \n",
        "                        if step % log_every == 0:\n",
        "                            print('running epoch: {}, step: {} out of {}, loss = {}...'.format(epoch, step, iter_count, average_loss))\n",
        "                            print()\n",
        "\n",
        "                        if min_loss > np_loss:\n",
        "                            saver.save(self.sess, \"./logs/\" + model_name + \"model_min_loss.ckpt\")\n",
        "                            print(\"minimal loss updated from {} to {} | at step {}...\".format(min_loss, np_loss, step))\n",
        "                            min_loss = np_loss\n",
        "                            print(\"Model weights and loss saved in ./logs/\" + model_name + \"model_min_loss.ckpt | at step {}...\".format(step))\n",
        "                            print()\n",
        "                        if step % save_every == 0:\n",
        "                            saver.save(self.sess, \"./logs/\" + model_name + \"model_default_save.ckpt\")\n",
        "                            print(\"Model with loss = {} saved to ./logs/\" + model_name + \"model_default_save.ckpt | at step {}...\".format(average_loss, step))\n",
        "                            print()\n",
        "                        if step % loss_every == 0:\n",
        "                            if len(losses) > 10000000:\n",
        "                                print('Already a lot losses...')\n",
        "                            else:\n",
        "                                losses.append(average_loss)\n",
        "                                print(\"Losses saved to ./logs/\" + model_name + \"losses_history... | at step {}\".format(step))\n",
        "                                print()\n",
        "                                np.save(\"./logs/\" + model_name + \"losses_history\", np.array(losses))\n",
        "                    epoch_losses.append(epoch_loss / iter_count)\n",
        "                    np.save(\"./logs/\" + model_name + \"epoch_losses\", np.array(epoch_losses))\n",
        "            except KeyboardInterrupt:\n",
        "                print('KeyboardInterrupt')\n",
        "    \n",
        "    def get_vectors_from_words(self, batcher, words):\n",
        "        if not isinstance(words, list):\n",
        "            words = [words]\n",
        "        with tf.device(device):\n",
        "            indexes = [batcher.word2index[word] for word in words]\n",
        "            x = tf.placeholder(dtype=tf.int32, shape=(len(indexes)))\n",
        "            x_one_hot = tf.one_hot(x, self.vocab_size)\n",
        "            x_one_hot = tf.cast(x_one_hot, tf.float32)\n",
        "            predicted = tf.matmul(x_one_hot, self.w1)\n",
        "           \n",
        "            embeddings = self.sess.run(predicted, feed_dict={x : indexes})\n",
        "            return embeddings\n",
        "    \n",
        "    def get_vectors_from_indexes(self, batcher, indexes):\n",
        "        words = [batcher.index2word[index] for index in indexes]\n",
        "        return self.get_vectors_from_words(batcher, words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QFSxTkrbK-yq",
        "colab_type": "code",
        "outputId": "06694855-2d5c-4753-872f-6dfd9d4cb5be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73457
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\"training the model (check tensorboard visualization) \"\"\"\n",
        "EMBEDDINGS_SIZE = 300\n",
        "BATCH_SIZE = 1024\n",
        "EPOCHS = 100\n",
        "LEARNING_RATE = 0.01\n",
        "model = Word2Vec(batcher.vocab_size, EMBEDDINGS_SIZE, batcher.window_size)\n",
        "model.train(batcher, BATCH_SIZE, EPOCHS, LEARNING_RATE)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting training...\n",
            "running epoch: 0, step: 0 out of 5859, loss = 140710.234375...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 0\n",
            "\n",
            "running epoch: 0, step: 75 out of 5859, loss = 77305.17310855263...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 100\n",
            "\n",
            "running epoch: 0, step: 150 out of 5859, loss = 63550.34964817881...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 200\n",
            "\n",
            "running epoch: 0, step: 225 out of 5859, loss = 58743.31078885509...\n",
            "\n",
            "running epoch: 0, step: 300 out of 5859, loss = 56362.353807620435...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 300\n",
            "\n",
            "running epoch: 0, step: 375 out of 5859, loss = 54740.98495678192...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 400\n",
            "\n",
            "running epoch: 0, step: 450 out of 5859, loss = 53570.41551759978...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 500\n",
            "\n",
            "running epoch: 0, step: 525 out of 5859, loss = 52679.593972789924...\n",
            "\n",
            "running epoch: 0, step: 600 out of 5859, loss = 51916.18927438644...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 600\n",
            "\n",
            "running epoch: 0, step: 675 out of 5859, loss = 51321.590259800294...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 700\n",
            "\n",
            "running epoch: 0, step: 750 out of 5859, loss = 50837.3978601448...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 800\n",
            "\n",
            "running epoch: 0, step: 825 out of 5859, loss = 50364.31046175091...\n",
            "\n",
            "running epoch: 0, step: 900 out of 5859, loss = 49986.216387173976...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 900\n",
            "\n",
            "running epoch: 0, step: 975 out of 5859, loss = 49665.793933305584...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1000\n",
            "\n",
            "running epoch: 0, step: 1050 out of 5859, loss = 49375.51395248573...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1100\n",
            "\n",
            "running epoch: 0, step: 1125 out of 5859, loss = 49071.33948642873...\n",
            "\n",
            "running epoch: 0, step: 1200 out of 5859, loss = 48818.64110962219...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1200\n",
            "\n",
            "running epoch: 0, step: 1275 out of 5859, loss = 48562.69969325529...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1300\n",
            "\n",
            "running epoch: 0, step: 1350 out of 5859, loss = 48315.25795417746...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1400\n",
            "\n",
            "running epoch: 0, step: 1425 out of 5859, loss = 48137.03088293303...\n",
            "\n",
            "running epoch: 0, step: 1500 out of 5859, loss = 47950.32238924051...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1500\n",
            "\n",
            "running epoch: 0, step: 1575 out of 5859, loss = 47802.94280665054...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1600\n",
            "\n",
            "running epoch: 0, step: 1650 out of 5859, loss = 47641.39623712901...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1700\n",
            "\n",
            "running epoch: 0, step: 1725 out of 5859, loss = 47475.4637958973...\n",
            "\n",
            "running epoch: 0, step: 1800 out of 5859, loss = 47325.893494499585...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1800\n",
            "\n",
            "running epoch: 0, step: 1875 out of 5859, loss = 47190.559455790244...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1900\n",
            "\n",
            "running epoch: 0, step: 1950 out of 5859, loss = 47016.41245475077...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2000\n",
            "\n",
            "running epoch: 0, step: 2025 out of 5859, loss = 46879.94041715511...\n",
            "\n",
            "running epoch: 0, step: 2100 out of 5859, loss = 46760.996711015585...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2100\n",
            "\n",
            "running epoch: 0, step: 2175 out of 5859, loss = 46627.8774988511...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2200\n",
            "\n",
            "running epoch: 0, step: 2250 out of 5859, loss = 46508.16345339571...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2300\n",
            "\n",
            "running epoch: 0, step: 2325 out of 5859, loss = 46377.190245794816...\n",
            "\n",
            "running epoch: 0, step: 2400 out of 5859, loss = 46262.23206313775...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2400\n",
            "\n",
            "running epoch: 0, step: 2475 out of 5859, loss = 46151.021228796446...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2500\n",
            "\n",
            "running epoch: 0, step: 2550 out of 5859, loss = 46067.5357442547...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2600\n",
            "\n",
            "running epoch: 0, step: 2625 out of 5859, loss = 45965.04282743479...\n",
            "\n",
            "running epoch: 0, step: 2700 out of 5859, loss = 45869.07849378703...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2700\n",
            "\n",
            "running epoch: 0, step: 2775 out of 5859, loss = 45775.32695425072...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2800\n",
            "\n",
            "running epoch: 0, step: 2850 out of 5859, loss = 45684.109280460805...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2900\n",
            "\n",
            "running epoch: 0, step: 2925 out of 5859, loss = 45606.859929030674...\n",
            "\n",
            "running epoch: 0, step: 3000 out of 5859, loss = 45504.21769956889...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3000\n",
            "\n",
            "running epoch: 0, step: 3075 out of 5859, loss = 45421.13639746221...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3100\n",
            "\n",
            "running epoch: 0, step: 3150 out of 5859, loss = 45340.892820483576...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3200\n",
            "\n",
            "running epoch: 0, step: 3225 out of 5859, loss = 45261.95570898559...\n",
            "\n",
            "running epoch: 0, step: 3300 out of 5859, loss = 45196.41893318313...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3300\n",
            "\n",
            "running epoch: 0, step: 3375 out of 5859, loss = 45116.92029676392...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3400\n",
            "\n",
            "running epoch: 0, step: 3450 out of 5859, loss = 45052.23807524087...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3500\n",
            "\n",
            "running epoch: 0, step: 3525 out of 5859, loss = 44987.24626989684...\n",
            "\n",
            "running epoch: 0, step: 3600 out of 5859, loss = 44951.54755081054...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3600\n",
            "\n",
            "running epoch: 0, step: 3675 out of 5859, loss = 44879.70235246362...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3700\n",
            "\n",
            "running epoch: 0, step: 3750 out of 5859, loss = 44812.21906033391...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3800\n",
            "\n",
            "running epoch: 0, step: 3825 out of 5859, loss = 44750.239203190344...\n",
            "\n",
            "running epoch: 0, step: 3900 out of 5859, loss = 44679.0840028999...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3900\n",
            "\n",
            "running epoch: 0, step: 3975 out of 5859, loss = 44615.607276471324...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4000\n",
            "\n",
            "running epoch: 0, step: 4050 out of 5859, loss = 44560.34767842817...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4100\n",
            "\n",
            "running epoch: 0, step: 4125 out of 5859, loss = 44496.02249644026...\n",
            "\n",
            "running epoch: 0, step: 4200 out of 5859, loss = 44435.57075789246...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4200\n",
            "\n",
            "running epoch: 0, step: 4275 out of 5859, loss = 44369.69491785547...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4300\n",
            "\n",
            "running epoch: 0, step: 4350 out of 5859, loss = 44323.150338104744...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4400\n",
            "\n",
            "running epoch: 0, step: 4425 out of 5859, loss = 44262.99265173125...\n",
            "\n",
            "running epoch: 0, step: 4500 out of 5859, loss = 44218.63603921351...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4500\n",
            "\n",
            "running epoch: 0, step: 4575 out of 5859, loss = 44172.67880739865...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4600\n",
            "\n",
            "running epoch: 0, step: 4650 out of 5859, loss = 44152.54051212105...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4700\n",
            "\n",
            "running epoch: 0, step: 4725 out of 5859, loss = 44100.31821555623...\n",
            "\n",
            "running epoch: 0, step: 4800 out of 5859, loss = 44054.31423710555...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4800\n",
            "\n",
            "running epoch: 0, step: 4875 out of 5859, loss = 44011.09205323267...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4900\n",
            "\n",
            "running epoch: 0, step: 4950 out of 5859, loss = 43958.85582694784...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5000\n",
            "\n",
            "running epoch: 0, step: 5025 out of 5859, loss = 43911.77386574189...\n",
            "\n",
            "running epoch: 0, step: 5100 out of 5859, loss = 43861.227734911045...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5100\n",
            "\n",
            "running epoch: 0, step: 5175 out of 5859, loss = 43824.34803887534...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5200\n",
            "\n",
            "running epoch: 0, step: 5250 out of 5859, loss = 43793.49138556942...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5300\n",
            "\n",
            "running epoch: 0, step: 5325 out of 5859, loss = 43763.75695732022...\n",
            "\n",
            "running epoch: 0, step: 5400 out of 5859, loss = 43729.559814588734...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5400\n",
            "\n",
            "running epoch: 0, step: 5475 out of 5859, loss = 43695.395687574186...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5500\n",
            "\n",
            "running epoch: 0, step: 5550 out of 5859, loss = 43663.60787892947...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5600\n",
            "\n",
            "running epoch: 0, step: 5625 out of 5859, loss = 43630.57017433012...\n",
            "\n",
            "running epoch: 0, step: 5700 out of 5859, loss = 43601.21667868028...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5700\n",
            "\n",
            "running epoch: 0, step: 5775 out of 5859, loss = 43556.694440762425...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5800\n",
            "\n",
            "running epoch: 0, step: 5850 out of 5859, loss = 43528.3413819486...\n",
            "\n",
            "running epoch: 1, step: 0 out of 5859, loss = 43494.9921875...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 0\n",
            "\n",
            "running epoch: 1, step: 75 out of 5859, loss = 40948.05807976974...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 100\n",
            "\n",
            "running epoch: 1, step: 150 out of 5859, loss = 41145.23328849338...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 200\n",
            "\n",
            "running epoch: 1, step: 225 out of 5859, loss = 41102.553131913715...\n",
            "\n",
            "running epoch: 1, step: 300 out of 5859, loss = 41007.01693573505...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 300\n",
            "\n",
            "running epoch: 1, step: 375 out of 5859, loss = 40853.28224734042...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 400\n",
            "\n",
            "running epoch: 1, step: 450 out of 5859, loss = 40771.64716428769...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 500\n",
            "\n",
            "running epoch: 1, step: 525 out of 5859, loss = 40725.94780774715...\n",
            "\n",
            "running epoch: 1, step: 600 out of 5859, loss = 40711.45678426581...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 600\n",
            "\n",
            "running epoch: 1, step: 675 out of 5859, loss = 40741.26513382951...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 700\n",
            "\n",
            "running epoch: 1, step: 750 out of 5859, loss = 40730.61283913116...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 800\n",
            "\n",
            "running epoch: 1, step: 825 out of 5859, loss = 40693.553978132564...\n",
            "\n",
            "running epoch: 1, step: 900 out of 5859, loss = 40734.58759364595...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 900\n",
            "\n",
            "running epoch: 1, step: 975 out of 5859, loss = 40729.22910796619...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1000\n",
            "\n",
            "running epoch: 1, step: 1050 out of 5859, loss = 40723.96067361441...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1100\n",
            "\n",
            "running epoch: 1, step: 1125 out of 5859, loss = 40722.909642817496...\n",
            "\n",
            "running epoch: 1, step: 1200 out of 5859, loss = 40760.99659138218...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1200\n",
            "\n",
            "running epoch: 1, step: 1275 out of 5859, loss = 40777.5015398462...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1300\n",
            "\n",
            "running epoch: 1, step: 1350 out of 5859, loss = 40752.36181243061...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1400\n",
            "\n",
            "running epoch: 1, step: 1425 out of 5859, loss = 40756.549110273496...\n",
            "\n",
            "running epoch: 1, step: 1500 out of 5859, loss = 40732.2443371086...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1500\n",
            "\n",
            "running epoch: 1, step: 1575 out of 5859, loss = 40714.59598568369...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1600\n",
            "\n",
            "running epoch: 1, step: 1650 out of 5859, loss = 40721.9896251325...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1700\n",
            "\n",
            "running epoch: 1, step: 1725 out of 5859, loss = 40738.52261596538...\n",
            "\n",
            "running epoch: 1, step: 1800 out of 5859, loss = 40736.55425154428...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1800\n",
            "\n",
            "running epoch: 1, step: 1875 out of 5859, loss = 40743.79526544177...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1900\n",
            "\n",
            "running epoch: 1, step: 1950 out of 5859, loss = 40736.59948423885...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2000\n",
            "\n",
            "running epoch: 1, step: 2025 out of 5859, loss = 40716.46744470323...\n",
            "\n",
            "running epoch: 1, step: 2100 out of 5859, loss = 40709.574426984174...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2100\n",
            "\n",
            "running epoch: 1, step: 2175 out of 5859, loss = 40693.26264504826...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2200\n",
            "\n",
            "running epoch: 1, step: 2250 out of 5859, loss = 40691.750041648156...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2300\n",
            "\n",
            "running epoch: 1, step: 2325 out of 5859, loss = 40689.24882610974...\n",
            "\n",
            "running epoch: 1, step: 2400 out of 5859, loss = 40686.16194586891...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2400\n",
            "\n",
            "running epoch: 1, step: 2475 out of 5859, loss = 40674.91480557098...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2500\n",
            "\n",
            "running epoch: 1, step: 2550 out of 5859, loss = 40654.92198371962...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2600\n",
            "\n",
            "running epoch: 1, step: 2625 out of 5859, loss = 40644.4289065475...\n",
            "\n",
            "running epoch: 1, step: 2700 out of 5859, loss = 40628.33950533367...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2700\n",
            "\n",
            "running epoch: 1, step: 2775 out of 5859, loss = 40606.1895699185...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2800\n",
            "\n",
            "running epoch: 1, step: 2850 out of 5859, loss = 40586.180582197034...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2900\n",
            "\n",
            "running epoch: 1, step: 2925 out of 5859, loss = 40591.19708673317...\n",
            "\n",
            "running epoch: 1, step: 3000 out of 5859, loss = 40568.98335580848...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3000\n",
            "\n",
            "running epoch: 1, step: 3075 out of 5859, loss = 40548.93932232404...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3100\n",
            "\n",
            "running epoch: 1, step: 3150 out of 5859, loss = 40538.880757100924...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3200\n",
            "\n",
            "running epoch: 1, step: 3225 out of 5859, loss = 40520.65948300914...\n",
            "\n",
            "running epoch: 1, step: 3300 out of 5859, loss = 40540.67479196645...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3300\n",
            "\n",
            "running epoch: 1, step: 3375 out of 5859, loss = 40539.17729700459...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3400\n",
            "\n",
            "running epoch: 1, step: 3450 out of 5859, loss = 40534.05476447044...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3500\n",
            "\n",
            "running epoch: 1, step: 3525 out of 5859, loss = 40533.198619407616...\n",
            "\n",
            "running epoch: 1, step: 3600 out of 5859, loss = 40510.933792262564...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3600\n",
            "\n",
            "running epoch: 1, step: 3675 out of 5859, loss = 40503.3346453346...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3700\n",
            "\n",
            "running epoch: 1, step: 3750 out of 5859, loss = 40487.74719866369...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3800\n",
            "\n",
            "running epoch: 1, step: 3825 out of 5859, loss = 40470.05899499314...\n",
            "\n",
            "running epoch: 1, step: 3900 out of 5859, loss = 40460.311938245...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3900\n",
            "\n",
            "running epoch: 1, step: 3975 out of 5859, loss = 40453.88698597837...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4000\n",
            "\n",
            "running epoch: 1, step: 4050 out of 5859, loss = 40447.16496987626...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4100\n",
            "\n",
            "running epoch: 1, step: 4125 out of 5859, loss = 40434.43667822952...\n",
            "\n",
            "running epoch: 1, step: 4200 out of 5859, loss = 40431.58978424036...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4200\n",
            "\n",
            "running epoch: 1, step: 4275 out of 5859, loss = 40416.53193788734...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4300\n",
            "\n",
            "running epoch: 1, step: 4350 out of 5859, loss = 40408.86526804183...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4400\n",
            "\n",
            "running epoch: 1, step: 4425 out of 5859, loss = 40399.7482710475...\n",
            "\n",
            "running epoch: 1, step: 4500 out of 5859, loss = 40397.85321317485...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4500\n",
            "\n",
            "running epoch: 1, step: 4575 out of 5859, loss = 40390.434065812115...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4600\n",
            "\n",
            "running epoch: 1, step: 4650 out of 5859, loss = 40390.86074063373...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4700\n",
            "\n",
            "running epoch: 1, step: 4725 out of 5859, loss = 40379.78254106274...\n",
            "\n",
            "running epoch: 1, step: 4800 out of 5859, loss = 40372.15243487685...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4800\n",
            "\n",
            "running epoch: 1, step: 4875 out of 5859, loss = 40362.59223268304...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4900\n",
            "\n",
            "running epoch: 1, step: 4950 out of 5859, loss = 40349.08171486821...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5000\n",
            "\n",
            "running epoch: 1, step: 5025 out of 5859, loss = 40350.27332713639...\n",
            "\n",
            "running epoch: 1, step: 5100 out of 5859, loss = 40354.643083923496...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5100\n",
            "\n",
            "running epoch: 1, step: 5175 out of 5859, loss = 40351.157957852345...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5200\n",
            "\n",
            "running epoch: 1, step: 5250 out of 5859, loss = 40344.573107354554...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5300\n",
            "\n",
            "running epoch: 1, step: 5325 out of 5859, loss = 40326.65708317687...\n",
            "\n",
            "running epoch: 1, step: 5400 out of 5859, loss = 40327.37482352805...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5400\n",
            "\n",
            "running epoch: 1, step: 5475 out of 5859, loss = 40319.892496804234...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5500\n",
            "\n",
            "running epoch: 1, step: 5550 out of 5859, loss = 40306.78080948252...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5600\n",
            "\n",
            "running epoch: 1, step: 5625 out of 5859, loss = 40310.60068210096...\n",
            "\n",
            "running epoch: 1, step: 5700 out of 5859, loss = 40301.60540160169...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5700\n",
            "\n",
            "running epoch: 1, step: 5775 out of 5859, loss = 40290.59983457951...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5800\n",
            "\n",
            "running epoch: 1, step: 5850 out of 5859, loss = 40284.33632872586...\n",
            "\n",
            "running epoch: 2, step: 0 out of 5859, loss = 34412.5078125...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 0\n",
            "\n",
            "running epoch: 2, step: 75 out of 5859, loss = 39049.46525493421...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 100\n",
            "\n",
            "running epoch: 2, step: 150 out of 5859, loss = 39618.050315604305...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 200\n",
            "\n",
            "running epoch: 2, step: 225 out of 5859, loss = 39580.635681692474...\n",
            "\n",
            "running epoch: 2, step: 300 out of 5859, loss = 39499.791528239206...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 300\n",
            "\n",
            "running epoch: 2, step: 375 out of 5859, loss = 39560.34055019947...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 400\n",
            "\n",
            "running epoch: 2, step: 450 out of 5859, loss = 39602.07677383592...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 500\n",
            "\n",
            "running epoch: 2, step: 525 out of 5859, loss = 39609.692022635456...\n",
            "\n",
            "running epoch: 2, step: 600 out of 5859, loss = 39641.3840734193...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 600\n",
            "\n",
            "running epoch: 2, step: 675 out of 5859, loss = 39676.323380870934...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 700\n",
            "\n",
            "running epoch: 2, step: 750 out of 5859, loss = 39668.230120256325...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 800\n",
            "\n",
            "running epoch: 2, step: 825 out of 5859, loss = 39662.025750037836...\n",
            "\n",
            "running epoch: 2, step: 900 out of 5859, loss = 39721.608668319925...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 900\n",
            "\n",
            "running epoch: 2, step: 975 out of 5859, loss = 39737.756815925975...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1000\n",
            "\n",
            "running epoch: 2, step: 1050 out of 5859, loss = 39783.14633013202...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1100\n",
            "\n",
            "running epoch: 2, step: 1125 out of 5859, loss = 39789.82782665409...\n",
            "\n",
            "running epoch: 2, step: 1200 out of 5859, loss = 39776.67341017902...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1200\n",
            "\n",
            "running epoch: 2, step: 1275 out of 5859, loss = 39803.49363244514...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1300\n",
            "\n",
            "running epoch: 2, step: 1350 out of 5859, loss = 39774.716113064394...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1400\n",
            "\n",
            "running epoch: 2, step: 1425 out of 5859, loss = 39797.93882856329...\n",
            "\n",
            "running epoch: 2, step: 1500 out of 5859, loss = 39821.25806493588...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1500\n",
            "\n",
            "running epoch: 2, step: 1575 out of 5859, loss = 39807.817072989375...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1600\n",
            "\n",
            "running epoch: 2, step: 1650 out of 5859, loss = 39820.400985671564...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1700\n",
            "\n",
            "running epoch: 2, step: 1725 out of 5859, loss = 39834.105534382245...\n",
            "\n",
            "running epoch: 2, step: 1800 out of 5859, loss = 39817.98322329608...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1800\n",
            "\n",
            "running epoch: 2, step: 1875 out of 5859, loss = 39804.12870219217...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1900\n",
            "\n",
            "running epoch: 2, step: 1950 out of 5859, loss = 39776.47470247629...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2000\n",
            "\n",
            "running epoch: 2, step: 2025 out of 5859, loss = 39773.87743128393...\n",
            "\n",
            "running epoch: 2, step: 2100 out of 5859, loss = 39772.98465946275...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2100\n",
            "\n",
            "running epoch: 2, step: 2175 out of 5859, loss = 39767.73924345129...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2200\n",
            "\n",
            "running epoch: 2, step: 2250 out of 5859, loss = 39751.35091868891...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2300\n",
            "\n",
            "running epoch: 2, step: 2325 out of 5859, loss = 39740.22941577547...\n",
            "\n",
            "running epoch: 2, step: 2400 out of 5859, loss = 39733.83915881404...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2400\n",
            "\n",
            "running epoch: 2, step: 2475 out of 5859, loss = 39750.29319277564...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2500\n",
            "\n",
            "running epoch: 2, step: 2550 out of 5859, loss = 39748.31013726235...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2600\n",
            "\n",
            "running epoch: 2, step: 2625 out of 5859, loss = 39740.701640446496...\n",
            "\n",
            "running epoch: 2, step: 2700 out of 5859, loss = 39748.24225547251...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2700\n",
            "\n",
            "running epoch: 2, step: 2775 out of 5859, loss = 39744.480764251624...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2800\n",
            "\n",
            "running epoch: 2, step: 2850 out of 5859, loss = 39750.21339140872...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2900\n",
            "\n",
            "running epoch: 2, step: 2925 out of 5859, loss = 39762.68469914132...\n",
            "\n",
            "running epoch: 2, step: 3000 out of 5859, loss = 39771.292963543405...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3000\n",
            "\n",
            "running epoch: 2, step: 3075 out of 5859, loss = 39773.747328104684...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3100\n",
            "\n",
            "running epoch: 2, step: 3150 out of 5859, loss = 39761.20176878372...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3200\n",
            "\n",
            "running epoch: 2, step: 3225 out of 5859, loss = 39750.17923826914...\n",
            "\n",
            "running epoch: 2, step: 3300 out of 5859, loss = 39740.54685488299...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3300\n",
            "\n",
            "running epoch: 2, step: 3375 out of 5859, loss = 39727.53257715306...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3400\n",
            "\n",
            "running epoch: 2, step: 3450 out of 5859, loss = 39729.41878259925...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3500\n",
            "\n",
            "running epoch: 2, step: 3525 out of 5859, loss = 39728.64498214159...\n",
            "\n",
            "running epoch: 2, step: 3600 out of 5859, loss = 39721.73542505554...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3600\n",
            "\n",
            "running epoch: 2, step: 3675 out of 5859, loss = 39712.2626039258...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3700\n",
            "\n",
            "running epoch: 2, step: 3750 out of 5859, loss = 39713.06986366136...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3800\n",
            "\n",
            "running epoch: 2, step: 3825 out of 5859, loss = 39716.700422479415...\n",
            "\n",
            "running epoch: 2, step: 3900 out of 5859, loss = 39699.37991360389...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3900\n",
            "\n",
            "running epoch: 2, step: 3975 out of 5859, loss = 39684.21878635092...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4000\n",
            "\n",
            "running epoch: 2, step: 4050 out of 5859, loss = 39685.66034524654...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4100\n",
            "\n",
            "running epoch: 2, step: 4125 out of 5859, loss = 39680.44004105066...\n",
            "\n",
            "running epoch: 2, step: 4200 out of 5859, loss = 39671.16268540973...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4200\n",
            "\n",
            "running epoch: 2, step: 4275 out of 5859, loss = 39659.3148687807...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4300\n",
            "\n",
            "running epoch: 2, step: 4350 out of 5859, loss = 39669.73140603453...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4400\n",
            "\n",
            "running epoch: 2, step: 4425 out of 5859, loss = 39661.393814604045...\n",
            "\n",
            "running epoch: 2, step: 4500 out of 5859, loss = 39651.07431855421...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4500\n",
            "\n",
            "running epoch: 2, step: 4575 out of 5859, loss = 39656.30061222957...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4600\n",
            "\n",
            "running epoch: 2, step: 4650 out of 5859, loss = 39659.36855985272...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4700\n",
            "\n",
            "running epoch: 2, step: 4725 out of 5859, loss = 39661.417044673086...\n",
            "\n",
            "running epoch: 2, step: 4800 out of 5859, loss = 39652.01285864924...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4800\n",
            "\n",
            "running epoch: 2, step: 4875 out of 5859, loss = 39649.236027705854...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4900\n",
            "\n",
            "running epoch: 2, step: 4950 out of 5859, loss = 39640.09925867249...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5000\n",
            "\n",
            "running epoch: 2, step: 5025 out of 5859, loss = 39640.08010377288...\n",
            "\n",
            "running epoch: 2, step: 5100 out of 5859, loss = 39638.68577316335...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5100\n",
            "\n",
            "running epoch: 2, step: 5175 out of 5859, loss = 39639.591055774246...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5200\n",
            "\n",
            "running epoch: 2, step: 5250 out of 5859, loss = 39636.51387830889...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5300\n",
            "\n",
            "running epoch: 2, step: 5325 out of 5859, loss = 39639.40843488899...\n",
            "\n",
            "running epoch: 2, step: 5400 out of 5859, loss = 39632.22396894094...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5400\n",
            "\n",
            "running epoch: 2, step: 5475 out of 5859, loss = 39628.69693463523...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5500\n",
            "\n",
            "running epoch: 2, step: 5550 out of 5859, loss = 39625.96734470704...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5600\n",
            "\n",
            "running epoch: 2, step: 5625 out of 5859, loss = 39617.93790131754...\n",
            "\n",
            "running epoch: 2, step: 5700 out of 5859, loss = 39610.131909423784...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5700\n",
            "\n",
            "running epoch: 2, step: 5775 out of 5859, loss = 39610.177410432174...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5800\n",
            "\n",
            "running epoch: 2, step: 5850 out of 5859, loss = 39607.52956893053...\n",
            "\n",
            "running epoch: 3, step: 0 out of 5859, loss = 34790.96484375...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 0\n",
            "\n",
            "running epoch: 3, step: 75 out of 5859, loss = 39205.47301603619...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 100\n",
            "\n",
            "running epoch: 3, step: 150 out of 5859, loss = 39379.59680256622...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 200\n",
            "\n",
            "running epoch: 3, step: 225 out of 5859, loss = 39247.115234375...\n",
            "\n",
            "running epoch: 3, step: 300 out of 5859, loss = 39431.84930440199...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 300\n",
            "\n",
            "running epoch: 3, step: 375 out of 5859, loss = 39368.73683718417...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 400\n",
            "\n",
            "running epoch: 3, step: 450 out of 5859, loss = 39431.25362042683...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 500\n",
            "\n",
            "running epoch: 3, step: 525 out of 5859, loss = 39354.70294676806...\n",
            "\n",
            "running epoch: 3, step: 600 out of 5859, loss = 39381.572307872295...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 600\n",
            "\n",
            "running epoch: 3, step: 675 out of 5859, loss = 39388.95610091531...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 700\n",
            "\n",
            "running epoch: 3, step: 750 out of 5859, loss = 39451.52107606525...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 800\n",
            "\n",
            "running epoch: 3, step: 825 out of 5859, loss = 39511.81415991979...\n",
            "\n",
            "running epoch: 3, step: 900 out of 5859, loss = 39463.3567563818...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 900\n",
            "\n",
            "running epoch: 3, step: 975 out of 5859, loss = 39474.4632668417...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1000\n",
            "\n",
            "running epoch: 3, step: 1050 out of 5859, loss = 39497.16917667697...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1100\n",
            "\n",
            "running epoch: 3, step: 1125 out of 5859, loss = 39448.983264875664...\n",
            "\n",
            "running epoch: 3, step: 1200 out of 5859, loss = 39448.995420482934...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1200\n",
            "\n",
            "running epoch: 3, step: 1275 out of 5859, loss = 39437.80692532817...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1300\n",
            "\n",
            "running epoch: 3, step: 1350 out of 5859, loss = 39415.43073128701...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1400\n",
            "\n",
            "running epoch: 3, step: 1425 out of 5859, loss = 39385.76585784099...\n",
            "\n",
            "running epoch: 3, step: 1500 out of 5859, loss = 39390.58879236759...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1500\n",
            "\n",
            "running epoch: 3, step: 1575 out of 5859, loss = 39384.66920804251...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1600\n",
            "\n",
            "running epoch: 3, step: 1650 out of 5859, loss = 39380.81866813674...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1700\n",
            "\n",
            "running epoch: 3, step: 1725 out of 5859, loss = 39388.99780924102...\n",
            "\n",
            "running epoch: 3, step: 1800 out of 5859, loss = 39396.57548106954...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1800\n",
            "\n",
            "running epoch: 3, step: 1875 out of 5859, loss = 39404.14342350746...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1900\n",
            "\n",
            "running epoch: 3, step: 1950 out of 5859, loss = 39401.364506583166...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2000\n",
            "\n",
            "running epoch: 3, step: 2025 out of 5859, loss = 39396.40813757095...\n",
            "\n",
            "running epoch: 3, step: 2100 out of 5859, loss = 39398.2148604831...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2100\n",
            "\n",
            "running epoch: 3, step: 2175 out of 5859, loss = 39367.841105741616...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2200\n",
            "\n",
            "running epoch: 3, step: 2250 out of 5859, loss = 39352.33573967126...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2300\n",
            "\n",
            "running epoch: 3, step: 2325 out of 5859, loss = 39335.742746735275...\n",
            "\n",
            "running epoch: 3, step: 2400 out of 5859, loss = 39334.737928206996...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2400\n",
            "\n",
            "running epoch: 3, step: 2475 out of 5859, loss = 39333.92408212591...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2500\n",
            "\n",
            "running epoch: 3, step: 2550 out of 5859, loss = 39323.310291919835...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2600\n",
            "\n",
            "running epoch: 3, step: 2625 out of 5859, loss = 39331.125050575974...\n",
            "\n",
            "running epoch: 3, step: 2700 out of 5859, loss = 39333.178802411145...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2700\n",
            "\n",
            "running epoch: 3, step: 2775 out of 5859, loss = 39332.10249684798...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2800\n",
            "\n",
            "running epoch: 3, step: 2850 out of 5859, loss = 39341.738779978514...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2900\n",
            "\n",
            "running epoch: 3, step: 2925 out of 5859, loss = 39340.84890315277...\n",
            "\n",
            "running epoch: 3, step: 3000 out of 5859, loss = 39330.90181397867...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3000\n",
            "\n",
            "running epoch: 3, step: 3075 out of 5859, loss = 39310.599407458954...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3100\n",
            "\n",
            "running epoch: 3, step: 3150 out of 5859, loss = 39295.43536278166...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3200\n",
            "\n",
            "running epoch: 3, step: 3225 out of 5859, loss = 39291.102744304095...\n",
            "\n",
            "running epoch: 3, step: 3300 out of 5859, loss = 39285.99498968116...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3300\n",
            "\n",
            "running epoch: 3, step: 3375 out of 5859, loss = 39285.993670856784...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3400\n",
            "\n",
            "running epoch: 3, step: 3450 out of 5859, loss = 39300.576464475875...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3500\n",
            "\n",
            "running epoch: 3, step: 3525 out of 5859, loss = 39303.66299454056...\n",
            "\n",
            "running epoch: 3, step: 3600 out of 5859, loss = 39310.83760261907...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3600\n",
            "\n",
            "running epoch: 3, step: 3675 out of 5859, loss = 39317.56504713853...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3700\n",
            "\n",
            "running epoch: 3, step: 3750 out of 5859, loss = 39307.84782807918...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3800\n",
            "\n",
            "running epoch: 3, step: 3825 out of 5859, loss = 39304.531331677994...\n",
            "\n",
            "running epoch: 3, step: 3900 out of 5859, loss = 39307.770099013076...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3900\n",
            "\n",
            "running epoch: 3, step: 3975 out of 5859, loss = 39295.312940140844...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4000\n",
            "\n",
            "running epoch: 3, step: 4050 out of 5859, loss = 39287.249915144406...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4100\n",
            "\n",
            "running epoch: 3, step: 4125 out of 5859, loss = 39283.90343155447...\n",
            "\n",
            "running epoch: 3, step: 4200 out of 5859, loss = 39272.26194842002...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4200\n",
            "\n",
            "running epoch: 3, step: 4275 out of 5859, loss = 39268.92390212085...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4300\n",
            "\n",
            "running epoch: 3, step: 4350 out of 5859, loss = 39265.655365684615...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4400\n",
            "\n",
            "running epoch: 3, step: 4425 out of 5859, loss = 39273.868505175386...\n",
            "\n",
            "running epoch: 3, step: 4500 out of 5859, loss = 39262.52565488919...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4500\n",
            "\n",
            "running epoch: 3, step: 4575 out of 5859, loss = 39258.31498152726...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4600\n",
            "\n",
            "running epoch: 3, step: 4650 out of 5859, loss = 39273.68208365808...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4700\n",
            "\n",
            "running epoch: 3, step: 4725 out of 5859, loss = 39275.36481696995...\n",
            "\n",
            "running epoch: 3, step: 4800 out of 5859, loss = 39277.96031425745...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4800\n",
            "\n",
            "running epoch: 3, step: 4875 out of 5859, loss = 39275.07908233567...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4900\n",
            "\n",
            "running epoch: 3, step: 4950 out of 5859, loss = 39269.84724597935...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5000\n",
            "\n",
            "running epoch: 3, step: 5025 out of 5859, loss = 39261.47368838291...\n",
            "\n",
            "running epoch: 3, step: 5100 out of 5859, loss = 39260.83596813125...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5100\n",
            "\n",
            "running epoch: 3, step: 5175 out of 5859, loss = 39261.500068676345...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5200\n",
            "\n",
            "running epoch: 3, step: 5250 out of 5859, loss = 39253.54669571867...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5300\n",
            "\n",
            "running epoch: 3, step: 5325 out of 5859, loss = 39252.97531786871...\n",
            "\n",
            "running epoch: 3, step: 5400 out of 5859, loss = 39247.2862736646...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5400\n",
            "\n",
            "running epoch: 3, step: 5475 out of 5859, loss = 39256.42135426178...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5500\n",
            "\n",
            "running epoch: 3, step: 5550 out of 5859, loss = 39263.540364348766...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5600\n",
            "\n",
            "running epoch: 3, step: 5625 out of 5859, loss = 39262.65081624378...\n",
            "\n",
            "running epoch: 3, step: 5700 out of 5859, loss = 39260.24925040563...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5700\n",
            "\n",
            "running epoch: 3, step: 5775 out of 5859, loss = 39268.233727114355...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5800\n",
            "\n",
            "running epoch: 3, step: 5850 out of 5859, loss = 39275.583704975645...\n",
            "\n",
            "running epoch: 4, step: 0 out of 5859, loss = 43280.890625...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 0\n",
            "\n",
            "running epoch: 4, step: 75 out of 5859, loss = 38902.56070106908...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 100\n",
            "\n",
            "running epoch: 4, step: 150 out of 5859, loss = 38869.658707574505...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 200\n",
            "\n",
            "running epoch: 4, step: 225 out of 5859, loss = 39196.818670492255...\n",
            "\n",
            "running epoch: 4, step: 300 out of 5859, loss = 39159.42349719685...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 300\n",
            "\n",
            "running epoch: 4, step: 375 out of 5859, loss = 39162.896203873...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 400\n",
            "\n",
            "running epoch: 4, step: 450 out of 5859, loss = 39103.35376247228...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 500\n",
            "\n",
            "running epoch: 4, step: 525 out of 5859, loss = 39133.73077322956...\n",
            "\n",
            "running epoch: 4, step: 600 out of 5859, loss = 39128.831953254994...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 600\n",
            "\n",
            "running epoch: 4, step: 675 out of 5859, loss = 39110.001225036984...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 700\n",
            "\n",
            "running epoch: 4, step: 750 out of 5859, loss = 39120.667089713716...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 800\n",
            "\n",
            "running epoch: 4, step: 825 out of 5859, loss = 39139.77923539649...\n",
            "\n",
            "running epoch: 4, step: 900 out of 5859, loss = 39160.48388509295...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 900\n",
            "\n",
            "running epoch: 4, step: 975 out of 5859, loss = 39176.608874711834...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1000\n",
            "\n",
            "running epoch: 4, step: 1050 out of 5859, loss = 39138.499282677214...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1100\n",
            "\n",
            "running epoch: 4, step: 1125 out of 5859, loss = 39131.26645065497...\n",
            "\n",
            "running epoch: 4, step: 1200 out of 5859, loss = 39125.14914654454...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1200\n",
            "\n",
            "running epoch: 4, step: 1275 out of 5859, loss = 39081.89633590076...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1300\n",
            "\n",
            "running epoch: 4, step: 1350 out of 5859, loss = 39062.794982593914...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1400\n",
            "\n",
            "running epoch: 4, step: 1425 out of 5859, loss = 39065.10486199378...\n",
            "\n",
            "running epoch: 4, step: 1500 out of 5859, loss = 39059.15949653356...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1500\n",
            "\n",
            "running epoch: 4, step: 1575 out of 5859, loss = 39048.88709177705...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1600\n",
            "\n",
            "running epoch: 4, step: 1650 out of 5859, loss = 39051.605936033084...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1700\n",
            "\n",
            "running epoch: 4, step: 1725 out of 5859, loss = 39055.761701776144...\n",
            "\n",
            "running epoch: 4, step: 1800 out of 5859, loss = 39046.82453649882...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1800\n",
            "\n",
            "running epoch: 4, step: 1875 out of 5859, loss = 39064.64396592651...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1900\n",
            "\n",
            "running epoch: 4, step: 1950 out of 5859, loss = 39074.39814618305...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2000\n",
            "\n",
            "running epoch: 4, step: 2025 out of 5859, loss = 39060.0732421875...\n",
            "\n",
            "running epoch: 4, step: 2100 out of 5859, loss = 39039.691613554554...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2100\n",
            "\n",
            "running epoch: 4, step: 2175 out of 5859, loss = 39037.21721963322...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2200\n",
            "\n",
            "running epoch: 4, step: 2250 out of 5859, loss = 39042.493377075465...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2300\n",
            "\n",
            "running epoch: 4, step: 2325 out of 5859, loss = 39057.72149327574...\n",
            "\n",
            "running epoch: 4, step: 2400 out of 5859, loss = 39055.71204462333...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2400\n",
            "\n",
            "running epoch: 4, step: 2475 out of 5859, loss = 39052.81186815302...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2500\n",
            "\n",
            "running epoch: 4, step: 2550 out of 5859, loss = 39046.069683916845...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2600\n",
            "\n",
            "running epoch: 4, step: 2625 out of 5859, loss = 39055.59502555574...\n",
            "\n",
            "running epoch: 4, step: 2700 out of 5859, loss = 39057.049509296325...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2700\n",
            "\n",
            "running epoch: 4, step: 2775 out of 5859, loss = 39056.789748485906...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2800\n",
            "\n",
            "running epoch: 4, step: 2850 out of 5859, loss = 39042.76951549347...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2900\n",
            "\n",
            "running epoch: 4, step: 2925 out of 5859, loss = 39033.101492411784...\n",
            "\n",
            "running epoch: 4, step: 3000 out of 5859, loss = 39042.64901998813...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3000\n",
            "\n",
            "running epoch: 4, step: 3075 out of 5859, loss = 39042.80596185692...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3100\n",
            "\n",
            "running epoch: 4, step: 3150 out of 5859, loss = 39034.5468619833...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3200\n",
            "\n",
            "running epoch: 4, step: 3225 out of 5859, loss = 39026.358966333115...\n",
            "\n",
            "running epoch: 4, step: 3300 out of 5859, loss = 39033.942432809185...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3300\n",
            "\n",
            "running epoch: 4, step: 3375 out of 5859, loss = 39045.838326259814...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3400\n",
            "\n",
            "running epoch: 4, step: 3450 out of 5859, loss = 39036.33477558588...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3500\n",
            "\n",
            "running epoch: 4, step: 3525 out of 5859, loss = 39028.79173516821...\n",
            "\n",
            "running epoch: 4, step: 3600 out of 5859, loss = 39042.09278075968...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3600\n",
            "\n",
            "running epoch: 4, step: 3675 out of 5859, loss = 39045.893146103954...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3700\n",
            "\n",
            "running epoch: 4, step: 3750 out of 5859, loss = 39044.97821153943...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3800\n",
            "\n",
            "running epoch: 4, step: 3825 out of 5859, loss = 39051.32700039614...\n",
            "\n",
            "running epoch: 4, step: 3900 out of 5859, loss = 39049.51511881969...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3900\n",
            "\n",
            "running epoch: 4, step: 3975 out of 5859, loss = 39056.260997135156...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4000\n",
            "\n",
            "running epoch: 4, step: 4050 out of 5859, loss = 39053.178315828656...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4100\n",
            "\n",
            "running epoch: 4, step: 4125 out of 5859, loss = 39060.685403443866...\n",
            "\n",
            "running epoch: 4, step: 4200 out of 5859, loss = 39057.7908157098...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4200\n",
            "\n",
            "running epoch: 4, step: 4275 out of 5859, loss = 39057.35121398869...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4300\n",
            "\n",
            "running epoch: 4, step: 4350 out of 5859, loss = 39051.48412945659...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4400\n",
            "\n",
            "running epoch: 4, step: 4425 out of 5859, loss = 39053.421597432076...\n",
            "\n",
            "running epoch: 4, step: 4500 out of 5859, loss = 39053.081307886445...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4500\n",
            "\n",
            "running epoch: 4, step: 4575 out of 5859, loss = 39047.740614670976...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4600\n",
            "\n",
            "running epoch: 4, step: 4650 out of 5859, loss = 39039.90411966177...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4700\n",
            "\n",
            "running epoch: 4, step: 4725 out of 5859, loss = 39046.31989633477...\n",
            "\n",
            "running epoch: 4, step: 4800 out of 5859, loss = 39046.719393990184...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4800\n",
            "\n",
            "running epoch: 4, step: 4875 out of 5859, loss = 39049.345596175786...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4900\n",
            "\n",
            "running epoch: 4, step: 4950 out of 5859, loss = 39042.271564851166...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5000\n",
            "\n",
            "running epoch: 4, step: 5025 out of 5859, loss = 39039.47938726435...\n",
            "\n",
            "running epoch: 4, step: 5100 out of 5859, loss = 39039.784697164156...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5100\n",
            "\n",
            "running epoch: 4, step: 5175 out of 5859, loss = 39034.08505338642...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5200\n",
            "\n",
            "running epoch: 4, step: 5250 out of 5859, loss = 39025.31304714281...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5300\n",
            "\n",
            "running epoch: 4, step: 5325 out of 5859, loss = 39021.51718683991...\n",
            "\n",
            "running epoch: 4, step: 5400 out of 5859, loss = 39017.92766566666...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5400\n",
            "\n",
            "running epoch: 4, step: 5475 out of 5859, loss = 39014.654631788144...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5500\n",
            "\n",
            "running epoch: 4, step: 5550 out of 5859, loss = 39012.83332008028...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5600\n",
            "\n",
            "running epoch: 4, step: 5625 out of 5859, loss = 39009.31601986036...\n",
            "\n",
            "running epoch: 4, step: 5700 out of 5859, loss = 39014.13000015074...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5700\n",
            "\n",
            "running epoch: 4, step: 5775 out of 5859, loss = 39019.30452552859...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5800\n",
            "\n",
            "running epoch: 4, step: 5850 out of 5859, loss = 39011.19874173485...\n",
            "\n",
            "running epoch: 5, step: 0 out of 5859, loss = 40613.02734375...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 0\n",
            "\n",
            "running epoch: 5, step: 75 out of 5859, loss = 39362.14319490131...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 100\n",
            "\n",
            "running epoch: 5, step: 150 out of 5859, loss = 39119.21010968543...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 200\n",
            "\n",
            "running epoch: 5, step: 225 out of 5859, loss = 39009.082083102876...\n",
            "\n",
            "running epoch: 5, step: 300 out of 5859, loss = 38883.54922394103...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 300\n",
            "\n",
            "running epoch: 5, step: 375 out of 5859, loss = 38907.355811585774...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 400\n",
            "\n",
            "running epoch: 5, step: 450 out of 5859, loss = 38882.64092814579...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 500\n",
            "\n",
            "running epoch: 5, step: 525 out of 5859, loss = 38976.60445876901...\n",
            "\n",
            "running epoch: 5, step: 600 out of 5859, loss = 38960.07521968594...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 600\n",
            "\n",
            "running epoch: 5, step: 675 out of 5859, loss = 38943.916795719306...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 700\n",
            "\n",
            "running epoch: 5, step: 750 out of 5859, loss = 38914.141186750996...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 800\n",
            "\n",
            "running epoch: 5, step: 825 out of 5859, loss = 38978.627109185836...\n",
            "\n",
            "running epoch: 5, step: 900 out of 5859, loss = 38991.36567008879...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 900\n",
            "\n",
            "running epoch: 5, step: 975 out of 5859, loss = 39023.65388063525...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1000\n",
            "\n",
            "running epoch: 5, step: 1050 out of 5859, loss = 39059.279897121785...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1100\n",
            "\n",
            "running epoch: 5, step: 1125 out of 5859, loss = 39033.369074711365...\n",
            "\n",
            "running epoch: 5, step: 1200 out of 5859, loss = 39026.49306567444...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1200\n",
            "\n",
            "running epoch: 5, step: 1275 out of 5859, loss = 38975.75106227958...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1300\n",
            "\n",
            "running epoch: 5, step: 1350 out of 5859, loss = 38994.728768620465...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1400\n",
            "\n",
            "running epoch: 5, step: 1425 out of 5859, loss = 38984.21816926718...\n",
            "\n",
            "running epoch: 5, step: 1500 out of 5859, loss = 38976.779691143405...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1500\n",
            "\n",
            "running epoch: 5, step: 1575 out of 5859, loss = 38966.442766993176...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1600\n",
            "\n",
            "running epoch: 5, step: 1650 out of 5859, loss = 38987.898939089944...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1700\n",
            "\n",
            "running epoch: 5, step: 1725 out of 5859, loss = 38967.941284038236...\n",
            "\n",
            "running epoch: 5, step: 1800 out of 5859, loss = 38969.498650923095...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1800\n",
            "\n",
            "running epoch: 5, step: 1875 out of 5859, loss = 38974.35660147921...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1900\n",
            "\n",
            "running epoch: 5, step: 1950 out of 5859, loss = 38974.136738771784...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2000\n",
            "\n",
            "running epoch: 5, step: 2025 out of 5859, loss = 38979.31684006355...\n",
            "\n",
            "running epoch: 5, step: 2100 out of 5859, loss = 38976.4079660727...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2100\n",
            "\n",
            "running epoch: 5, step: 2175 out of 5859, loss = 38978.17428947898...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2200\n",
            "\n",
            "running epoch: 5, step: 2250 out of 5859, loss = 38964.10205186584...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2300\n",
            "\n",
            "running epoch: 5, step: 2325 out of 5859, loss = 38971.127144574915...\n",
            "\n",
            "running epoch: 5, step: 2400 out of 5859, loss = 38964.108114132134...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2400\n",
            "\n",
            "running epoch: 5, step: 2475 out of 5859, loss = 38968.325406716984...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2500\n",
            "\n",
            "running epoch: 5, step: 2550 out of 5859, loss = 38957.961251408764...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2600\n",
            "\n",
            "running epoch: 5, step: 2625 out of 5859, loss = 38949.3068905298...\n",
            "\n",
            "running epoch: 5, step: 2700 out of 5859, loss = 38948.14505622917...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2700\n",
            "\n",
            "running epoch: 5, step: 2775 out of 5859, loss = 38971.49639769452...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2800\n",
            "\n",
            "running epoch: 5, step: 2850 out of 5859, loss = 38965.64272267406...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2900\n",
            "\n",
            "running epoch: 5, step: 2925 out of 5859, loss = 38964.47513537038...\n",
            "\n",
            "running epoch: 5, step: 3000 out of 5859, loss = 38965.58518514662...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3000\n",
            "\n",
            "running epoch: 5, step: 3075 out of 5859, loss = 38964.790676558434...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3100\n",
            "\n",
            "running epoch: 5, step: 3150 out of 5859, loss = 38975.764234072514...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3200\n",
            "\n",
            "running epoch: 5, step: 3225 out of 5859, loss = 38989.96190982447...\n",
            "\n",
            "running epoch: 5, step: 3300 out of 5859, loss = 39005.13028012345...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3300\n",
            "\n",
            "running epoch: 5, step: 3375 out of 5859, loss = 39015.18661715973...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3400\n",
            "\n",
            "running epoch: 5, step: 3450 out of 5859, loss = 38996.950278225515...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3500\n",
            "\n",
            "running epoch: 5, step: 3525 out of 5859, loss = 38992.78682244399...\n",
            "\n",
            "running epoch: 5, step: 3600 out of 5859, loss = 39001.55143428041...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3600\n",
            "\n",
            "running epoch: 5, step: 3675 out of 5859, loss = 39006.45991630679...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3700\n",
            "\n",
            "running epoch: 5, step: 3750 out of 5859, loss = 39008.98565070148...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3800\n",
            "\n",
            "running epoch: 5, step: 3825 out of 5859, loss = 39016.82457507024...\n",
            "\n",
            "running epoch: 5, step: 3900 out of 5859, loss = 39012.860008851894...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3900\n",
            "\n",
            "running epoch: 5, step: 3975 out of 5859, loss = 39015.24109697246...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4000\n",
            "\n",
            "running epoch: 5, step: 4050 out of 5859, loss = 39009.26179107011...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4100\n",
            "\n",
            "running epoch: 5, step: 4125 out of 5859, loss = 39006.0015573876...\n",
            "\n",
            "running epoch: 5, step: 4200 out of 5859, loss = 39001.81509424839...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4200\n",
            "\n",
            "running epoch: 5, step: 4275 out of 5859, loss = 38993.80572161483...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4300\n",
            "\n",
            "running epoch: 5, step: 4350 out of 5859, loss = 39010.82703419473...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4400\n",
            "\n",
            "running epoch: 5, step: 4425 out of 5859, loss = 39008.43642238336...\n",
            "\n",
            "running epoch: 5, step: 4500 out of 5859, loss = 39007.74757085231...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4500\n",
            "\n",
            "running epoch: 5, step: 4575 out of 5859, loss = 39003.65296946705...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4600\n",
            "\n",
            "running epoch: 5, step: 4650 out of 5859, loss = 39008.8968173847...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4700\n",
            "\n",
            "running epoch: 5, step: 4725 out of 5859, loss = 39017.16725709506...\n",
            "\n",
            "running epoch: 5, step: 4800 out of 5859, loss = 39010.288407525775...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4800\n",
            "\n",
            "running epoch: 5, step: 4875 out of 5859, loss = 38992.69059391663...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4900\n",
            "\n",
            "running epoch: 5, step: 4950 out of 5859, loss = 38978.49673203646...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5000\n",
            "\n",
            "running epoch: 5, step: 5025 out of 5859, loss = 38972.55438050264...\n",
            "\n",
            "running epoch: 5, step: 5100 out of 5859, loss = 38969.51672236449...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5100\n",
            "\n",
            "running epoch: 5, step: 5175 out of 5859, loss = 38969.5942307344...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5200\n",
            "\n",
            "running epoch: 5, step: 5250 out of 5859, loss = 38969.90556411874...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5300\n",
            "\n",
            "running epoch: 5, step: 5325 out of 5859, loss = 38970.77069373709...\n",
            "\n",
            "running epoch: 5, step: 5400 out of 5859, loss = 38961.36898259581...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5400\n",
            "\n",
            "running epoch: 5, step: 5475 out of 5859, loss = 38959.48284131894...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5500\n",
            "\n",
            "running epoch: 5, step: 5550 out of 5859, loss = 38953.43932118087...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5600\n",
            "\n",
            "running epoch: 5, step: 5625 out of 5859, loss = 38947.26090708874...\n",
            "\n",
            "running epoch: 5, step: 5700 out of 5859, loss = 38944.06643845378...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5700\n",
            "\n",
            "running epoch: 5, step: 5775 out of 5859, loss = 38939.29197595654...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5800\n",
            "\n",
            "running epoch: 5, step: 5850 out of 5859, loss = 38942.6609987876...\n",
            "\n",
            "running epoch: 6, step: 0 out of 5859, loss = 38577.109375...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 0\n",
            "\n",
            "running epoch: 6, step: 75 out of 5859, loss = 38855.26099917763...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 100\n",
            "\n",
            "running epoch: 6, step: 150 out of 5859, loss = 39087.971155836094...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 200\n",
            "\n",
            "running epoch: 6, step: 225 out of 5859, loss = 39032.07511753318...\n",
            "\n",
            "running epoch: 6, step: 300 out of 5859, loss = 39182.84656613372...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 300\n",
            "\n",
            "running epoch: 6, step: 375 out of 5859, loss = 39185.448096742024...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 400\n",
            "\n",
            "running epoch: 6, step: 450 out of 5859, loss = 39063.20138407705...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 500\n",
            "\n",
            "running epoch: 6, step: 525 out of 5859, loss = 39022.80386317728...\n",
            "\n",
            "running epoch: 6, step: 600 out of 5859, loss = 39011.721869800334...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 600\n",
            "\n",
            "running epoch: 6, step: 675 out of 5859, loss = 38979.444370608355...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 700\n",
            "\n",
            "running epoch: 6, step: 750 out of 5859, loss = 38997.60722682257...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 800\n",
            "\n",
            "running epoch: 6, step: 825 out of 5859, loss = 39019.58306219734...\n",
            "\n",
            "running epoch: 6, step: 900 out of 5859, loss = 39010.95671909684...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 900\n",
            "\n",
            "running epoch: 6, step: 975 out of 5859, loss = 39017.500208119876...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1000\n",
            "\n",
            "running epoch: 6, step: 1050 out of 5859, loss = 39046.425948501426...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1100\n",
            "\n",
            "running epoch: 6, step: 1125 out of 5859, loss = 39038.785714781305...\n",
            "\n",
            "running epoch: 6, step: 1200 out of 5859, loss = 39041.780853195254...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1200\n",
            "\n",
            "running epoch: 6, step: 1275 out of 5859, loss = 38998.37372036638...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1300\n",
            "\n",
            "running epoch: 6, step: 1350 out of 5859, loss = 38964.33503539045...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1400\n",
            "\n",
            "running epoch: 6, step: 1425 out of 5859, loss = 38944.40175205996...\n",
            "\n",
            "running epoch: 6, step: 1500 out of 5859, loss = 38951.07269892988...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1500\n",
            "\n",
            "running epoch: 6, step: 1575 out of 5859, loss = 38927.75084271891...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1600\n",
            "\n",
            "running epoch: 6, step: 1650 out of 5859, loss = 38906.79589548001...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1700\n",
            "\n",
            "running epoch: 6, step: 1725 out of 5859, loss = 38902.328779059244...\n",
            "\n",
            "running epoch: 6, step: 1800 out of 5859, loss = 38912.99538884647...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1800\n",
            "\n",
            "running epoch: 6, step: 1875 out of 5859, loss = 38920.192343250266...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1900\n",
            "\n",
            "running epoch: 6, step: 1950 out of 5859, loss = 38905.75155769477...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2000\n",
            "\n",
            "running epoch: 6, step: 2025 out of 5859, loss = 38886.43176209279...\n",
            "\n",
            "running epoch: 6, step: 2100 out of 5859, loss = 38885.25230916825...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2100\n",
            "\n",
            "running epoch: 6, step: 2175 out of 5859, loss = 38866.909217385684...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2200\n",
            "\n",
            "running epoch: 6, step: 2250 out of 5859, loss = 38864.00048589516...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2300\n",
            "\n",
            "running epoch: 6, step: 2325 out of 5859, loss = 38862.78021885748...\n",
            "\n",
            "running epoch: 6, step: 2400 out of 5859, loss = 38855.4706876692...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2400\n",
            "\n",
            "running epoch: 6, step: 2475 out of 5859, loss = 38858.55984324515...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2500\n",
            "\n",
            "running epoch: 6, step: 2550 out of 5859, loss = 38856.5345559952...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2600\n",
            "\n",
            "running epoch: 6, step: 2625 out of 5859, loss = 38856.21007027085...\n",
            "\n",
            "running epoch: 6, step: 2700 out of 5859, loss = 38857.1469739217...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2700\n",
            "\n",
            "running epoch: 6, step: 2775 out of 5859, loss = 38858.94704048091...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2800\n",
            "\n",
            "running epoch: 6, step: 2850 out of 5859, loss = 38848.21443682042...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2900\n",
            "\n",
            "running epoch: 6, step: 2925 out of 5859, loss = 38862.641393967875...\n",
            "\n",
            "running epoch: 6, step: 3000 out of 5859, loss = 38861.70427695976...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3000\n",
            "\n",
            "running epoch: 6, step: 3075 out of 5859, loss = 38868.966050166615...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3100\n",
            "\n",
            "running epoch: 6, step: 3150 out of 5859, loss = 38862.32676754404...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3200\n",
            "\n",
            "running epoch: 6, step: 3225 out of 5859, loss = 38863.209427551534...\n",
            "\n",
            "running epoch: 6, step: 3300 out of 5859, loss = 38850.350224127156...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3300\n",
            "\n",
            "running epoch: 6, step: 3375 out of 5859, loss = 38857.11810620927...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3400\n",
            "\n",
            "running epoch: 6, step: 3450 out of 5859, loss = 38850.17464027637...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3500\n",
            "\n",
            "running epoch: 6, step: 3525 out of 5859, loss = 38847.74440539918...\n",
            "\n",
            "running epoch: 6, step: 3600 out of 5859, loss = 38857.302981159744...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3600\n",
            "\n",
            "running epoch: 6, step: 3675 out of 5859, loss = 38858.1399523514...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3700\n",
            "\n",
            "running epoch: 6, step: 3750 out of 5859, loss = 38851.64134043422...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3800\n",
            "\n",
            "running epoch: 6, step: 3825 out of 5859, loss = 38853.656581816846...\n",
            "\n",
            "running epoch: 6, step: 3900 out of 5859, loss = 38841.788597875544...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3900\n",
            "\n",
            "running epoch: 6, step: 3975 out of 5859, loss = 38843.14698051591...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4000\n",
            "\n",
            "running epoch: 6, step: 4050 out of 5859, loss = 38842.795800805354...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4100\n",
            "\n",
            "running epoch: 6, step: 4125 out of 5859, loss = 38833.9806760861...\n",
            "\n",
            "running epoch: 6, step: 4200 out of 5859, loss = 38827.59442971167...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4200\n",
            "\n",
            "running epoch: 6, step: 4275 out of 5859, loss = 38816.02198316183...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4300\n",
            "\n",
            "running epoch: 6, step: 4350 out of 5859, loss = 38834.99870001149...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4400\n",
            "\n",
            "running epoch: 6, step: 4425 out of 5859, loss = 38832.24741583823...\n",
            "\n",
            "running epoch: 6, step: 4500 out of 5859, loss = 38833.886082606645...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4500\n",
            "\n",
            "running epoch: 6, step: 4575 out of 5859, loss = 38831.3741275814...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4600\n",
            "\n",
            "running epoch: 6, step: 4650 out of 5859, loss = 38830.53705856267...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4700\n",
            "\n",
            "running epoch: 6, step: 4725 out of 5859, loss = 38835.15422827179...\n",
            "\n",
            "running epoch: 6, step: 4800 out of 5859, loss = 38836.44501308321...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4800\n",
            "\n",
            "running epoch: 6, step: 4875 out of 5859, loss = 38838.61676210649...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4900\n",
            "\n",
            "running epoch: 6, step: 4950 out of 5859, loss = 38839.28231749268...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5000\n",
            "\n",
            "running epoch: 6, step: 5025 out of 5859, loss = 38838.29781386789...\n",
            "\n",
            "running epoch: 6, step: 5100 out of 5859, loss = 38840.01381316163...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5100\n",
            "\n",
            "running epoch: 6, step: 5175 out of 5859, loss = 38835.403684825396...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5200\n",
            "\n",
            "running epoch: 6, step: 5250 out of 5859, loss = 38836.25992519282...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5300\n",
            "\n",
            "running epoch: 6, step: 5325 out of 5859, loss = 38840.25403606717...\n",
            "\n",
            "running epoch: 6, step: 5400 out of 5859, loss = 38836.15791491159...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5400\n",
            "\n",
            "running epoch: 6, step: 5475 out of 5859, loss = 38834.08096266664...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5500\n",
            "\n",
            "running epoch: 6, step: 5550 out of 5859, loss = 38835.53177214691...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5600\n",
            "\n",
            "running epoch: 6, step: 5625 out of 5859, loss = 38827.198236285774...\n",
            "\n",
            "running epoch: 6, step: 5700 out of 5859, loss = 38822.061957332044...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5700\n",
            "\n",
            "running epoch: 6, step: 5775 out of 5859, loss = 38819.47199416227...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5800\n",
            "\n",
            "running epoch: 6, step: 5850 out of 5859, loss = 38818.280163780764...\n",
            "\n",
            "running epoch: 7, step: 0 out of 5859, loss = 37650.7265625...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 0\n",
            "\n",
            "running epoch: 7, step: 75 out of 5859, loss = 38508.26624177631...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 100\n",
            "\n",
            "running epoch: 7, step: 150 out of 5859, loss = 38704.41923634106...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 200\n",
            "\n",
            "running epoch: 7, step: 225 out of 5859, loss = 38699.47632051991...\n",
            "\n",
            "running epoch: 7, step: 300 out of 5859, loss = 38633.87658326412...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 300\n",
            "\n",
            "running epoch: 7, step: 375 out of 5859, loss = 38644.222323803195...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 400\n",
            "\n",
            "running epoch: 7, step: 450 out of 5859, loss = 38698.71701773836...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 500\n",
            "\n",
            "running epoch: 7, step: 525 out of 5859, loss = 38683.27006594582...\n",
            "\n",
            "running epoch: 7, step: 600 out of 5859, loss = 38723.43511465266...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 600\n",
            "\n",
            "running epoch: 7, step: 675 out of 5859, loss = 38710.39014538647...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 700\n",
            "\n",
            "running epoch: 7, step: 750 out of 5859, loss = 38709.553584803594...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 800\n",
            "\n",
            "running epoch: 7, step: 825 out of 5859, loss = 38741.147931484564...\n",
            "\n",
            "running epoch: 7, step: 900 out of 5859, loss = 38764.78297551332...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 900\n",
            "\n",
            "running epoch: 7, step: 975 out of 5859, loss = 38733.25406233991...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1000\n",
            "\n",
            "running epoch: 7, step: 1050 out of 5859, loss = 38725.31057103354...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1100\n",
            "\n",
            "running epoch: 7, step: 1125 out of 5859, loss = 38758.349755078816...\n",
            "\n",
            "running epoch: 7, step: 1200 out of 5859, loss = 38768.80730250833...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1200\n",
            "\n",
            "running epoch: 7, step: 1275 out of 5859, loss = 38782.639357611675...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1300\n",
            "\n",
            "running epoch: 7, step: 1350 out of 5859, loss = 38794.06787217801...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1400\n",
            "\n",
            "running epoch: 7, step: 1425 out of 5859, loss = 38803.44760529891...\n",
            "\n",
            "running epoch: 7, step: 1500 out of 5859, loss = 38843.39841407812...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1500\n",
            "\n",
            "running epoch: 7, step: 1575 out of 5859, loss = 38806.02969840577...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1600\n",
            "\n",
            "running epoch: 7, step: 1650 out of 5859, loss = 38789.179659108115...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1700\n",
            "\n",
            "running epoch: 7, step: 1725 out of 5859, loss = 38812.005241526655...\n",
            "\n",
            "running epoch: 7, step: 1800 out of 5859, loss = 38813.40839724459...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1800\n",
            "\n",
            "running epoch: 7, step: 1875 out of 5859, loss = 38811.456864672175...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1900\n",
            "\n",
            "running epoch: 7, step: 1950 out of 5859, loss = 38799.64701795553...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2000\n",
            "\n",
            "running epoch: 7, step: 2025 out of 5859, loss = 38796.990201597975...\n",
            "\n",
            "running epoch: 7, step: 2100 out of 5859, loss = 38814.721194892314...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2100\n",
            "\n",
            "running epoch: 7, step: 2175 out of 5859, loss = 38801.4519850787...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2200\n",
            "\n",
            "running epoch: 7, step: 2250 out of 5859, loss = 38803.814250957905...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2300\n",
            "\n",
            "running epoch: 7, step: 2325 out of 5859, loss = 38787.64195675247...\n",
            "\n",
            "running epoch: 7, step: 2400 out of 5859, loss = 38807.30014186797...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2400\n",
            "\n",
            "running epoch: 7, step: 2475 out of 5859, loss = 38800.08795215317...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2500\n",
            "\n",
            "running epoch: 7, step: 2550 out of 5859, loss = 38802.66048547138...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2600\n",
            "\n",
            "running epoch: 7, step: 2625 out of 5859, loss = 38800.736802646614...\n",
            "\n",
            "running epoch: 7, step: 2700 out of 5859, loss = 38792.87823520224...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2700\n",
            "\n",
            "running epoch: 7, step: 2775 out of 5859, loss = 38792.786841312816...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2800\n",
            "\n",
            "running epoch: 7, step: 2850 out of 5859, loss = 38793.11091571488...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2900\n",
            "\n",
            "running epoch: 7, step: 2925 out of 5859, loss = 38815.35321591443...\n",
            "\n",
            "running epoch: 7, step: 3000 out of 5859, loss = 38823.644797437315...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3000\n",
            "\n",
            "running epoch: 7, step: 3075 out of 5859, loss = 38818.52776409095...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3100\n",
            "\n",
            "running epoch: 7, step: 3150 out of 5859, loss = 38820.78034626904...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3200\n",
            "\n",
            "running epoch: 7, step: 3225 out of 5859, loss = 38833.74042569165...\n",
            "\n",
            "running epoch: 7, step: 3300 out of 5859, loss = 38838.125394056726...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3300\n",
            "\n",
            "running epoch: 7, step: 3375 out of 5859, loss = 38863.33485217343...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3400\n",
            "\n",
            "running epoch: 7, step: 3450 out of 5859, loss = 38865.37342663358...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3500\n",
            "\n",
            "running epoch: 7, step: 3525 out of 5859, loss = 38852.25325040769...\n",
            "\n",
            "running epoch: 7, step: 3600 out of 5859, loss = 38841.98678535476...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3600\n",
            "\n",
            "running epoch: 7, step: 3675 out of 5859, loss = 38853.30095658494...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3700\n",
            "\n",
            "running epoch: 7, step: 3750 out of 5859, loss = 38869.385257681286...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3800\n",
            "\n",
            "running epoch: 7, step: 3825 out of 5859, loss = 38868.60293979515...\n",
            "\n",
            "running epoch: 7, step: 3900 out of 5859, loss = 38861.12493591387...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3900\n",
            "\n",
            "running epoch: 7, step: 3975 out of 5859, loss = 38849.442913339415...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4000\n",
            "\n",
            "running epoch: 7, step: 4050 out of 5859, loss = 38850.68636987781...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4100\n",
            "\n",
            "running epoch: 7, step: 4125 out of 5859, loss = 38850.11544360458...\n",
            "\n",
            "running epoch: 7, step: 4200 out of 5859, loss = 38869.41967593281...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4200\n",
            "\n",
            "running epoch: 7, step: 4275 out of 5859, loss = 38871.01990671042...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4300\n",
            "\n",
            "running epoch: 7, step: 4350 out of 5859, loss = 38868.5832513359...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4400\n",
            "\n",
            "running epoch: 7, step: 4425 out of 5859, loss = 38874.12912336195...\n",
            "\n",
            "running epoch: 7, step: 4500 out of 5859, loss = 38879.24481278466...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4500\n",
            "\n",
            "running epoch: 7, step: 4575 out of 5859, loss = 38875.56118198208...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4600\n",
            "\n",
            "running epoch: 7, step: 4650 out of 5859, loss = 38883.24109818453...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4700\n",
            "\n",
            "running epoch: 7, step: 4725 out of 5859, loss = 38881.39326994287...\n",
            "\n",
            "running epoch: 7, step: 4800 out of 5859, loss = 38885.69261856254...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4800\n",
            "\n",
            "running epoch: 7, step: 4875 out of 5859, loss = 38885.975618783326...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4900\n",
            "\n",
            "running epoch: 7, step: 4950 out of 5859, loss = 38885.64900083317...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5000\n",
            "\n",
            "running epoch: 7, step: 5025 out of 5859, loss = 38883.31099299269...\n",
            "\n",
            "running epoch: 7, step: 5100 out of 5859, loss = 38886.29860183665...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5100\n",
            "\n",
            "running epoch: 7, step: 5175 out of 5859, loss = 38879.855307247395...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5200\n",
            "\n",
            "running epoch: 7, step: 5250 out of 5859, loss = 38875.36358476362...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5300\n",
            "\n",
            "running epoch: 7, step: 5325 out of 5859, loss = 38879.40791121972...\n",
            "\n",
            "running epoch: 7, step: 5400 out of 5859, loss = 38875.99874082924...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5400\n",
            "\n",
            "running epoch: 7, step: 5475 out of 5859, loss = 38877.18516666476...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5500\n",
            "\n",
            "running epoch: 7, step: 5550 out of 5859, loss = 38868.92408532809...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5600\n",
            "\n",
            "running epoch: 7, step: 5625 out of 5859, loss = 38867.08145357492...\n",
            "\n",
            "running epoch: 7, step: 5700 out of 5859, loss = 38867.27667295212...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5700\n",
            "\n",
            "running epoch: 7, step: 5775 out of 5859, loss = 38859.368111311895...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5800\n",
            "\n",
            "running epoch: 7, step: 5850 out of 5859, loss = 38851.883179023884...\n",
            "\n",
            "running epoch: 8, step: 0 out of 5859, loss = 46706.5...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 0\n",
            "\n",
            "running epoch: 8, step: 75 out of 5859, loss = 38488.22836143092...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 100\n",
            "\n",
            "running epoch: 8, step: 150 out of 5859, loss = 38758.04172702815...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 200\n",
            "\n",
            "running epoch: 8, step: 225 out of 5859, loss = 38844.680171460175...\n",
            "\n",
            "running epoch: 8, step: 300 out of 5859, loss = 38780.70771906146...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 300\n",
            "\n",
            "running epoch: 8, step: 375 out of 5859, loss = 38623.37129114029...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 400\n",
            "\n",
            "running epoch: 8, step: 450 out of 5859, loss = 38505.88515105322...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 500\n",
            "\n",
            "running epoch: 8, step: 525 out of 5859, loss = 38455.42604117158...\n",
            "\n",
            "running epoch: 8, step: 600 out of 5859, loss = 38565.53716462146...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 600\n",
            "\n",
            "running epoch: 8, step: 675 out of 5859, loss = 38575.81148298817...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 700\n",
            "\n",
            "running epoch: 8, step: 750 out of 5859, loss = 38561.92517268642...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 800\n",
            "\n",
            "running epoch: 8, step: 825 out of 5859, loss = 38618.48971417222...\n",
            "\n",
            "running epoch: 8, step: 900 out of 5859, loss = 38692.87822991815...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 900\n",
            "\n",
            "running epoch: 8, step: 975 out of 5859, loss = 38726.04211225666...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1000\n",
            "\n",
            "running epoch: 8, step: 1050 out of 5859, loss = 38717.803732308515...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1100\n",
            "\n",
            "running epoch: 8, step: 1125 out of 5859, loss = 38717.60169085813...\n",
            "\n",
            "running epoch: 8, step: 1200 out of 5859, loss = 38725.02362289238...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1200\n",
            "\n",
            "running epoch: 8, step: 1275 out of 5859, loss = 38771.456345513325...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1300\n",
            "\n",
            "running epoch: 8, step: 1350 out of 5859, loss = 38741.44813159234...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1400\n",
            "\n",
            "running epoch: 8, step: 1425 out of 5859, loss = 38724.21224414885...\n",
            "\n",
            "running epoch: 8, step: 1500 out of 5859, loss = 38729.590840481345...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1500\n",
            "\n",
            "running epoch: 8, step: 1575 out of 5859, loss = 38730.43889792195...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1600\n",
            "\n",
            "running epoch: 8, step: 1650 out of 5859, loss = 38714.357134407175...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1700\n",
            "\n",
            "running epoch: 8, step: 1725 out of 5859, loss = 38694.034520296205...\n",
            "\n",
            "running epoch: 8, step: 1800 out of 5859, loss = 38703.75720736744...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1800\n",
            "\n",
            "running epoch: 8, step: 1875 out of 5859, loss = 38716.10390083622...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1900\n",
            "\n",
            "running epoch: 8, step: 1950 out of 5859, loss = 38741.873198039466...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2000\n",
            "\n",
            "running epoch: 8, step: 2025 out of 5859, loss = 38771.853635164734...\n",
            "\n",
            "running epoch: 8, step: 2100 out of 5859, loss = 38757.37173332639...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2100\n",
            "\n",
            "running epoch: 8, step: 2175 out of 5859, loss = 38756.12980562098...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2200\n",
            "\n",
            "running epoch: 8, step: 2250 out of 5859, loss = 38757.82581873334...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2300\n",
            "\n",
            "running epoch: 8, step: 2325 out of 5859, loss = 38768.97878600602...\n",
            "\n",
            "running epoch: 8, step: 2400 out of 5859, loss = 38776.42338641451...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2400\n",
            "\n",
            "running epoch: 8, step: 2475 out of 5859, loss = 38752.324392291...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2500\n",
            "\n",
            "running epoch: 8, step: 2550 out of 5859, loss = 38753.59583404792...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2600\n",
            "\n",
            "running epoch: 8, step: 2625 out of 5859, loss = 38751.82351663652...\n",
            "\n",
            "running epoch: 8, step: 2700 out of 5859, loss = 38736.87170405637...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2700\n",
            "\n",
            "running epoch: 8, step: 2775 out of 5859, loss = 38758.90128697992...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2800\n",
            "\n",
            "running epoch: 8, step: 2850 out of 5859, loss = 38760.30047022974...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2900\n",
            "\n",
            "running epoch: 8, step: 2925 out of 5859, loss = 38762.332473139526...\n",
            "\n",
            "running epoch: 8, step: 3000 out of 5859, loss = 38773.58447054107...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3000\n",
            "\n",
            "running epoch: 8, step: 3075 out of 5859, loss = 38780.23945845863...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3100\n",
            "\n",
            "running epoch: 8, step: 3150 out of 5859, loss = 38776.51470391344...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3200\n",
            "\n",
            "running epoch: 8, step: 3225 out of 5859, loss = 38771.15703221869...\n",
            "\n",
            "running epoch: 8, step: 3300 out of 5859, loss = 38774.86389659384...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3300\n",
            "\n",
            "running epoch: 8, step: 3375 out of 5859, loss = 38758.71072691425...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3400\n",
            "\n",
            "running epoch: 8, step: 3450 out of 5859, loss = 38752.402244141194...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3500\n",
            "\n",
            "running epoch: 8, step: 3525 out of 5859, loss = 38750.82425974015...\n",
            "\n",
            "running epoch: 8, step: 3600 out of 5859, loss = 38743.35609900028...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3600\n",
            "\n",
            "running epoch: 8, step: 3675 out of 5859, loss = 38757.89969566104...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3700\n",
            "\n",
            "running epoch: 8, step: 3750 out of 5859, loss = 38762.958960943746...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3800\n",
            "\n",
            "running epoch: 8, step: 3825 out of 5859, loss = 38762.0061197236...\n",
            "\n",
            "running epoch: 8, step: 3900 out of 5859, loss = 38771.634514787875...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3900\n",
            "\n",
            "running epoch: 8, step: 3975 out of 5859, loss = 38774.9107260752...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4000\n",
            "\n",
            "running epoch: 8, step: 4050 out of 5859, loss = 38789.839523612995...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4100\n",
            "\n",
            "running epoch: 8, step: 4125 out of 5859, loss = 38790.34863328587...\n",
            "\n",
            "running epoch: 8, step: 4200 out of 5859, loss = 38781.12061953255...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4200\n",
            "\n",
            "running epoch: 8, step: 4275 out of 5859, loss = 38790.32068613336...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4300\n",
            "\n",
            "running epoch: 8, step: 4350 out of 5859, loss = 38797.61324264537...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4400\n",
            "\n",
            "running epoch: 8, step: 4425 out of 5859, loss = 38793.64897145419...\n",
            "\n",
            "running epoch: 8, step: 4500 out of 5859, loss = 38792.55926807931...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4500\n",
            "\n",
            "running epoch: 8, step: 4575 out of 5859, loss = 38798.825152630576...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4600\n",
            "\n",
            "running epoch: 8, step: 4650 out of 5859, loss = 38793.83885773893...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4700\n",
            "\n",
            "running epoch: 8, step: 4725 out of 5859, loss = 38790.888466065386...\n",
            "\n",
            "running epoch: 8, step: 4800 out of 5859, loss = 38792.92699274891...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4800\n",
            "\n",
            "running epoch: 8, step: 4875 out of 5859, loss = 38792.82743043094...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4900\n",
            "\n",
            "running epoch: 8, step: 4950 out of 5859, loss = 38786.199793128915...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5000\n",
            "\n",
            "running epoch: 8, step: 5025 out of 5859, loss = 38785.422308682355...\n",
            "\n",
            "running epoch: 8, step: 5100 out of 5859, loss = 38789.6688739034...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5100\n",
            "\n",
            "running epoch: 8, step: 5175 out of 5859, loss = 38793.418624194...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5200\n",
            "\n",
            "running epoch: 8, step: 5250 out of 5859, loss = 38796.20482817261...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5300\n",
            "\n",
            "running epoch: 8, step: 5325 out of 5859, loss = 38784.6369846185...\n",
            "\n",
            "running epoch: 8, step: 5400 out of 5859, loss = 38791.1097485564...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5400\n",
            "\n",
            "running epoch: 8, step: 5475 out of 5859, loss = 38787.53707763137...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5500\n",
            "\n",
            "running epoch: 8, step: 5550 out of 5859, loss = 38786.60893764919...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5600\n",
            "\n",
            "running epoch: 8, step: 5625 out of 5859, loss = 38786.859953716565...\n",
            "\n",
            "running epoch: 8, step: 5700 out of 5859, loss = 38784.22419757773...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5700\n",
            "\n",
            "running epoch: 8, step: 5775 out of 5859, loss = 38785.75052513905...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5800\n",
            "\n",
            "running epoch: 8, step: 5850 out of 5859, loss = 38775.36832212175...\n",
            "\n",
            "running epoch: 9, step: 0 out of 5859, loss = 36461.1953125...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 0\n",
            "\n",
            "running epoch: 9, step: 75 out of 5859, loss = 38361.77425986842...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 100\n",
            "\n",
            "running epoch: 9, step: 150 out of 5859, loss = 38858.83001345199...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 200\n",
            "\n",
            "running epoch: 9, step: 225 out of 5859, loss = 38950.16114145465...\n",
            "\n",
            "running epoch: 9, step: 300 out of 5859, loss = 38862.78481883305...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 300\n",
            "\n",
            "running epoch: 9, step: 375 out of 5859, loss = 38915.96844872008...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 400\n",
            "\n",
            "running epoch: 9, step: 450 out of 5859, loss = 38813.947114052105...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 500\n",
            "\n",
            "running epoch: 9, step: 525 out of 5859, loss = 38715.032690708176...\n",
            "\n",
            "running epoch: 9, step: 600 out of 5859, loss = 38669.587880875624...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 600\n",
            "\n",
            "running epoch: 9, step: 675 out of 5859, loss = 38688.53988304364...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 700\n",
            "\n",
            "running epoch: 9, step: 750 out of 5859, loss = 38635.9589661701...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 800\n",
            "\n",
            "running epoch: 9, step: 825 out of 5859, loss = 38661.870814732145...\n",
            "\n",
            "running epoch: 9, step: 900 out of 5859, loss = 38681.786782047726...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 900\n",
            "\n",
            "running epoch: 9, step: 975 out of 5859, loss = 38706.8807873335...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1000\n",
            "\n",
            "running epoch: 9, step: 1050 out of 5859, loss = 38716.00446747146...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1100\n",
            "\n",
            "running epoch: 9, step: 1125 out of 5859, loss = 38660.85905583925...\n",
            "\n",
            "running epoch: 9, step: 1200 out of 5859, loss = 38679.170160933594...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1200\n",
            "\n",
            "running epoch: 9, step: 1275 out of 5859, loss = 38666.624329569946...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1300\n",
            "\n",
            "running epoch: 9, step: 1350 out of 5859, loss = 38674.02580553757...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1400\n",
            "\n",
            "running epoch: 9, step: 1425 out of 5859, loss = 38682.26109418829...\n",
            "\n",
            "running epoch: 9, step: 1500 out of 5859, loss = 38693.26032905147...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1500\n",
            "\n",
            "running epoch: 9, step: 1575 out of 5859, loss = 38686.42749395225...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1600\n",
            "\n",
            "running epoch: 9, step: 1650 out of 5859, loss = 38667.56209778165...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1700\n",
            "\n",
            "running epoch: 9, step: 1725 out of 5859, loss = 38674.19069108488...\n",
            "\n",
            "running epoch: 9, step: 1800 out of 5859, loss = 38648.97794627985...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1800\n",
            "\n",
            "running epoch: 9, step: 1875 out of 5859, loss = 38657.195589435636...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1900\n",
            "\n",
            "running epoch: 9, step: 1950 out of 5859, loss = 38661.876369490004...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2000\n",
            "\n",
            "running epoch: 9, step: 2025 out of 5859, loss = 38680.713553877715...\n",
            "\n",
            "running epoch: 9, step: 2100 out of 5859, loss = 38663.3972513089...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2100\n",
            "\n",
            "running epoch: 9, step: 2175 out of 5859, loss = 38680.88701315487...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2200\n",
            "\n",
            "running epoch: 9, step: 2250 out of 5859, loss = 38672.644848817195...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2300\n",
            "\n",
            "running epoch: 9, step: 2325 out of 5859, loss = 38707.99922244465...\n",
            "\n",
            "running epoch: 9, step: 2400 out of 5859, loss = 38716.27914638432...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2400\n",
            "\n",
            "running epoch: 9, step: 2475 out of 5859, loss = 38717.416186010705...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2500\n",
            "\n",
            "running epoch: 9, step: 2550 out of 5859, loss = 38709.67366963936...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2600\n",
            "\n",
            "running epoch: 9, step: 2625 out of 5859, loss = 38694.33832200828...\n",
            "\n",
            "running epoch: 9, step: 2700 out of 5859, loss = 38672.80823074787...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2700\n",
            "\n",
            "running epoch: 9, step: 2775 out of 5859, loss = 38672.011164332675...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2800\n",
            "\n",
            "running epoch: 9, step: 2850 out of 5859, loss = 38681.92719111715...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2900\n",
            "\n",
            "running epoch: 9, step: 2925 out of 5859, loss = 38682.27815143327...\n",
            "\n",
            "running epoch: 9, step: 3000 out of 5859, loss = 38683.24199615753...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3000\n",
            "\n",
            "running epoch: 9, step: 3075 out of 5859, loss = 38698.2650535395...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3100\n",
            "\n",
            "running epoch: 9, step: 3150 out of 5859, loss = 38684.46074162964...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3200\n",
            "\n",
            "running epoch: 9, step: 3225 out of 5859, loss = 38679.33131078541...\n",
            "\n",
            "running epoch: 9, step: 3300 out of 5859, loss = 38672.57468499129...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3300\n",
            "\n",
            "running epoch: 9, step: 3375 out of 5859, loss = 38680.45311342936...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3400\n",
            "\n",
            "running epoch: 9, step: 3450 out of 5859, loss = 38663.87488454433...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3500\n",
            "\n",
            "running epoch: 9, step: 3525 out of 5859, loss = 38667.95491859579...\n",
            "\n",
            "running epoch: 9, step: 3600 out of 5859, loss = 38660.463202495834...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3600\n",
            "\n",
            "running epoch: 9, step: 3675 out of 5859, loss = 38647.98908779074...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3700\n",
            "\n",
            "running epoch: 9, step: 3750 out of 5859, loss = 38646.711171812516...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3800\n",
            "\n",
            "running epoch: 9, step: 3825 out of 5859, loss = 38640.05623938186...\n",
            "\n",
            "running epoch: 9, step: 3900 out of 5859, loss = 38652.52353763458...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3900\n",
            "\n",
            "running epoch: 9, step: 3975 out of 5859, loss = 38652.279328313634...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4000\n",
            "\n",
            "running epoch: 9, step: 4050 out of 5859, loss = 38647.86562634997...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4100\n",
            "\n",
            "running epoch: 9, step: 4125 out of 5859, loss = 38650.485549904566...\n",
            "\n",
            "running epoch: 9, step: 4200 out of 5859, loss = 38650.32488358427...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4200\n",
            "\n",
            "running epoch: 9, step: 4275 out of 5859, loss = 38639.81044730034...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4300\n",
            "\n",
            "running epoch: 9, step: 4350 out of 5859, loss = 38645.70053669415...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4400\n",
            "\n",
            "running epoch: 9, step: 4425 out of 5859, loss = 38647.6905686921...\n",
            "\n",
            "running epoch: 9, step: 4500 out of 5859, loss = 38650.29053699872...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4500\n",
            "\n",
            "running epoch: 9, step: 4575 out of 5859, loss = 38651.2343639027...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4600\n",
            "\n",
            "running epoch: 9, step: 4650 out of 5859, loss = 38653.74312605824...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4700\n",
            "\n",
            "running epoch: 9, step: 4725 out of 5859, loss = 38651.98712450077...\n",
            "\n",
            "running epoch: 9, step: 4800 out of 5859, loss = 38646.982742446235...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4800\n",
            "\n",
            "running epoch: 9, step: 4875 out of 5859, loss = 38641.329718823705...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4900\n",
            "\n",
            "running epoch: 9, step: 4950 out of 5859, loss = 38636.30590371579...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5000\n",
            "\n",
            "running epoch: 9, step: 5025 out of 5859, loss = 38643.2657893796...\n",
            "\n",
            "running epoch: 9, step: 5100 out of 5859, loss = 38637.53454630526...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5100\n",
            "\n",
            "running epoch: 9, step: 5175 out of 5859, loss = 38651.15698694999...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5200\n",
            "\n",
            "running epoch: 9, step: 5250 out of 5859, loss = 38652.23292698712...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5300\n",
            "\n",
            "running epoch: 9, step: 5325 out of 5859, loss = 38655.59553846989...\n",
            "\n",
            "running epoch: 9, step: 5400 out of 5859, loss = 38662.02691595017...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5400\n",
            "\n",
            "running epoch: 9, step: 5475 out of 5859, loss = 38655.070215842425...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5500\n",
            "\n",
            "running epoch: 9, step: 5550 out of 5859, loss = 38660.57002433402...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5600\n",
            "\n",
            "running epoch: 9, step: 5625 out of 5859, loss = 38658.17400413538...\n",
            "\n",
            "running epoch: 9, step: 5700 out of 5859, loss = 38652.214366517386...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5700\n",
            "\n",
            "running epoch: 9, step: 5775 out of 5859, loss = 38651.375670541354...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5800\n",
            "\n",
            "running epoch: 9, step: 5850 out of 5859, loss = 38646.85278190961...\n",
            "\n",
            "running epoch: 10, step: 0 out of 5859, loss = 45523.25390625...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 0\n",
            "\n",
            "running epoch: 10, step: 75 out of 5859, loss = 39892.33758223684...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 100\n",
            "\n",
            "running epoch: 10, step: 150 out of 5859, loss = 39422.818682740064...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 200\n",
            "\n",
            "running epoch: 10, step: 225 out of 5859, loss = 39208.39480779867...\n",
            "\n",
            "running epoch: 10, step: 300 out of 5859, loss = 38881.428169123756...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 300\n",
            "\n",
            "running epoch: 10, step: 375 out of 5859, loss = 38776.96251662234...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 400\n",
            "\n",
            "running epoch: 10, step: 450 out of 5859, loss = 38877.098253880264...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 500\n",
            "\n",
            "running epoch: 10, step: 525 out of 5859, loss = 38843.05016857771...\n",
            "\n",
            "running epoch: 10, step: 600 out of 5859, loss = 38828.74187227018...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 600\n",
            "\n",
            "running epoch: 10, step: 675 out of 5859, loss = 38890.61709215514...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 700\n",
            "\n",
            "running epoch: 10, step: 750 out of 5859, loss = 38879.27469363765...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 800\n",
            "\n",
            "running epoch: 10, step: 825 out of 5859, loss = 38817.389813956564...\n",
            "\n",
            "running epoch: 10, step: 900 out of 5859, loss = 38843.055014827274...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 900\n",
            "\n",
            "running epoch: 10, step: 975 out of 5859, loss = 38794.30895595863...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1000\n",
            "\n",
            "running epoch: 10, step: 1050 out of 5859, loss = 38810.17762659075...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1100\n",
            "\n",
            "running epoch: 10, step: 1125 out of 5859, loss = 38806.37980302231...\n",
            "\n",
            "running epoch: 10, step: 1200 out of 5859, loss = 38851.41133853299...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1200\n",
            "\n",
            "running epoch: 10, step: 1275 out of 5859, loss = 38805.84850882886...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1300\n",
            "\n",
            "running epoch: 10, step: 1350 out of 5859, loss = 38815.02876486168...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1400\n",
            "\n",
            "running epoch: 10, step: 1425 out of 5859, loss = 38802.95861319907...\n",
            "\n",
            "running epoch: 10, step: 1500 out of 5859, loss = 38787.303543731265...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1500\n",
            "\n",
            "running epoch: 10, step: 1575 out of 5859, loss = 38769.38707938412...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1600\n",
            "\n",
            "running epoch: 10, step: 1650 out of 5859, loss = 38725.32527989666...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1700\n",
            "\n",
            "running epoch: 10, step: 1725 out of 5859, loss = 38735.14412048269...\n",
            "\n",
            "running epoch: 10, step: 1800 out of 5859, loss = 38760.601754450654...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1800\n",
            "\n",
            "running epoch: 10, step: 1875 out of 5859, loss = 38740.18123771489...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1900\n",
            "\n",
            "running epoch: 10, step: 1950 out of 5859, loss = 38728.57495354946...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2000\n",
            "\n",
            "running epoch: 10, step: 2025 out of 5859, loss = 38767.48303114203...\n",
            "\n",
            "running epoch: 10, step: 2100 out of 5859, loss = 38777.87608021478...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2100\n",
            "\n",
            "running epoch: 10, step: 2175 out of 5859, loss = 38778.40654260972...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2200\n",
            "\n",
            "running epoch: 10, step: 2250 out of 5859, loss = 38754.46543029487...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2300\n",
            "\n",
            "running epoch: 10, step: 2325 out of 5859, loss = 38752.518429573305...\n",
            "\n",
            "running epoch: 10, step: 2400 out of 5859, loss = 38750.87240993336...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2400\n",
            "\n",
            "running epoch: 10, step: 2475 out of 5859, loss = 38746.164759819265...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2500\n",
            "\n",
            "running epoch: 10, step: 2550 out of 5859, loss = 38731.717690366524...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2600\n",
            "\n",
            "running epoch: 10, step: 2625 out of 5859, loss = 38723.69978549838...\n",
            "\n",
            "running epoch: 10, step: 2700 out of 5859, loss = 38729.47135754119...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2700\n",
            "\n",
            "running epoch: 10, step: 2775 out of 5859, loss = 38718.64113157421...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2800\n",
            "\n",
            "running epoch: 10, step: 2850 out of 5859, loss = 38718.72896297352...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2900\n",
            "\n",
            "running epoch: 10, step: 2925 out of 5859, loss = 38714.90698559253...\n",
            "\n",
            "running epoch: 10, step: 3000 out of 5859, loss = 38734.0930314895...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3000\n",
            "\n",
            "running epoch: 10, step: 3075 out of 5859, loss = 38723.77167232201...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3100\n",
            "\n",
            "running epoch: 10, step: 3150 out of 5859, loss = 38722.02497223104...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3200\n",
            "\n",
            "running epoch: 10, step: 3225 out of 5859, loss = 38718.43986724078...\n",
            "\n",
            "running epoch: 10, step: 3300 out of 5859, loss = 38703.759251457894...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3300\n",
            "\n",
            "running epoch: 10, step: 3375 out of 5859, loss = 38705.86576546764...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3400\n",
            "\n",
            "running epoch: 10, step: 3450 out of 5859, loss = 38709.137363943424...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3500\n",
            "\n",
            "running epoch: 10, step: 3525 out of 5859, loss = 38715.21827252021...\n",
            "\n",
            "running epoch: 10, step: 3600 out of 5859, loss = 38715.96754265308...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3600\n",
            "\n",
            "running epoch: 10, step: 3675 out of 5859, loss = 38715.26758768872...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3700\n",
            "\n",
            "running epoch: 10, step: 3750 out of 5859, loss = 38710.957004173884...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3800\n",
            "\n",
            "running epoch: 10, step: 3825 out of 5859, loss = 38719.17846845596...\n",
            "\n",
            "running epoch: 10, step: 3900 out of 5859, loss = 38716.40488917105...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3900\n",
            "\n",
            "running epoch: 10, step: 3975 out of 5859, loss = 38734.57744808696...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4000\n",
            "\n",
            "running epoch: 10, step: 4050 out of 5859, loss = 38726.167836645276...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4100\n",
            "\n",
            "running epoch: 10, step: 4125 out of 5859, loss = 38722.13960914778...\n",
            "\n",
            "running epoch: 10, step: 4200 out of 5859, loss = 38713.137290600454...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4200\n",
            "\n",
            "running epoch: 10, step: 4275 out of 5859, loss = 38718.91696295457...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4300\n",
            "\n",
            "running epoch: 10, step: 4350 out of 5859, loss = 38728.03120241755...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4400\n",
            "\n",
            "running epoch: 10, step: 4425 out of 5859, loss = 38722.9976267722...\n",
            "\n",
            "running epoch: 10, step: 4500 out of 5859, loss = 38733.126970916186...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4500\n",
            "\n",
            "running epoch: 10, step: 4575 out of 5859, loss = 38739.06061687336...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4600\n",
            "\n",
            "running epoch: 10, step: 4650 out of 5859, loss = 38721.826600630244...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4700\n",
            "\n",
            "running epoch: 10, step: 4725 out of 5859, loss = 38712.500438068666...\n",
            "\n",
            "running epoch: 10, step: 4800 out of 5859, loss = 38719.32271922516...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4800\n",
            "\n",
            "running epoch: 10, step: 4875 out of 5859, loss = 38721.685309744156...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4900\n",
            "\n",
            "running epoch: 10, step: 4950 out of 5859, loss = 38730.30300381236...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5000\n",
            "\n",
            "running epoch: 10, step: 5025 out of 5859, loss = 38732.75647803298...\n",
            "\n",
            "running epoch: 10, step: 5100 out of 5859, loss = 38723.67297466183...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5100\n",
            "\n",
            "running epoch: 10, step: 5175 out of 5859, loss = 38709.89398712206...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5200\n",
            "\n",
            "running epoch: 10, step: 5250 out of 5859, loss = 38704.04113799753...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5300\n",
            "\n",
            "running epoch: 10, step: 5325 out of 5859, loss = 38695.784114045484...\n",
            "\n",
            "running epoch: 10, step: 5400 out of 5859, loss = 38696.83136080124...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5400\n",
            "\n",
            "running epoch: 10, step: 5475 out of 5859, loss = 38697.47245865481...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5500\n",
            "\n",
            "running epoch: 10, step: 5550 out of 5859, loss = 38701.28174048032...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5600\n",
            "\n",
            "running epoch: 10, step: 5625 out of 5859, loss = 38700.46471738358...\n",
            "\n",
            "running epoch: 10, step: 5700 out of 5859, loss = 38699.06436302293...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5700\n",
            "\n",
            "running epoch: 10, step: 5775 out of 5859, loss = 38702.26726162137...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5800\n",
            "\n",
            "running epoch: 10, step: 5850 out of 5859, loss = 38697.83027006601...\n",
            "\n",
            "running epoch: 11, step: 0 out of 5859, loss = 37878.66796875...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 0\n",
            "\n",
            "running epoch: 11, step: 75 out of 5859, loss = 38370.25704152961...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 100\n",
            "\n",
            "running epoch: 11, step: 150 out of 5859, loss = 38420.81247413079...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 200\n",
            "\n",
            "running epoch: 11, step: 225 out of 5859, loss = 38299.40467712942...\n",
            "\n",
            "running epoch: 11, step: 300 out of 5859, loss = 38334.52094580565...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 300\n",
            "\n",
            "running epoch: 11, step: 375 out of 5859, loss = 38392.38176321476...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 400\n",
            "\n",
            "running epoch: 11, step: 450 out of 5859, loss = 38426.91401053215...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 500\n",
            "\n",
            "running epoch: 11, step: 525 out of 5859, loss = 38466.87156160884...\n",
            "\n",
            "running epoch: 11, step: 600 out of 5859, loss = 38454.18954086938...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 600\n",
            "\n",
            "running epoch: 11, step: 675 out of 5859, loss = 38455.6348638591...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 700\n",
            "\n",
            "running epoch: 11, step: 750 out of 5859, loss = 38490.16101448069...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 800\n",
            "\n",
            "running epoch: 11, step: 825 out of 5859, loss = 38502.41674863802...\n",
            "\n",
            "running epoch: 11, step: 900 out of 5859, loss = 38478.052532776084...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 900\n",
            "\n",
            "running epoch: 11, step: 975 out of 5859, loss = 38507.87200227331...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1000\n",
            "\n",
            "running epoch: 11, step: 1050 out of 5859, loss = 38484.324114682444...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1100\n",
            "\n",
            "running epoch: 11, step: 1125 out of 5859, loss = 38509.640725605015...\n",
            "\n",
            "running epoch: 11, step: 1200 out of 5859, loss = 38507.73330167569...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1200\n",
            "\n",
            "running epoch: 11, step: 1275 out of 5859, loss = 38517.144849627744...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1300\n",
            "\n",
            "running epoch: 11, step: 1350 out of 5859, loss = 38532.434036130646...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1400\n",
            "\n",
            "running epoch: 11, step: 1425 out of 5859, loss = 38540.74373246844...\n",
            "\n",
            "running epoch: 11, step: 1500 out of 5859, loss = 38525.6327058003...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1500\n",
            "\n",
            "running epoch: 11, step: 1575 out of 5859, loss = 38545.21206029902...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1600\n",
            "\n",
            "running epoch: 11, step: 1650 out of 5859, loss = 38541.794553963504...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1700\n",
            "\n",
            "running epoch: 11, step: 1725 out of 5859, loss = 38553.15048794177...\n",
            "\n",
            "running epoch: 11, step: 1800 out of 5859, loss = 38573.986023389785...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1800\n",
            "\n",
            "running epoch: 11, step: 1875 out of 5859, loss = 38558.788142157515...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1900\n",
            "\n",
            "running epoch: 11, step: 1950 out of 5859, loss = 38567.02539362827...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2000\n",
            "\n",
            "running epoch: 11, step: 2025 out of 5859, loss = 38607.23446947495...\n",
            "\n",
            "running epoch: 11, step: 2100 out of 5859, loss = 38618.38949644515...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2100\n",
            "\n",
            "running epoch: 11, step: 2175 out of 5859, loss = 38615.31975600299...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2200\n",
            "\n",
            "running epoch: 11, step: 2250 out of 5859, loss = 38603.45898350733...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2300\n",
            "\n",
            "running epoch: 11, step: 2325 out of 5859, loss = 38608.000962287726...\n",
            "\n",
            "running epoch: 11, step: 2400 out of 5859, loss = 38618.528160466994...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2400\n",
            "\n",
            "running epoch: 11, step: 2475 out of 5859, loss = 38604.782321221224...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2500\n",
            "\n",
            "running epoch: 11, step: 2550 out of 5859, loss = 38614.9303689117...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2600\n",
            "\n",
            "running epoch: 11, step: 2625 out of 5859, loss = 38611.047935607865...\n",
            "\n",
            "running epoch: 11, step: 2700 out of 5859, loss = 38614.308407187156...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2700\n",
            "\n",
            "running epoch: 11, step: 2775 out of 5859, loss = 38621.24879407196...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2800\n",
            "\n",
            "running epoch: 11, step: 2850 out of 5859, loss = 38617.3174598825...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2900\n",
            "\n",
            "running epoch: 11, step: 2925 out of 5859, loss = 38609.11223326427...\n",
            "\n",
            "running epoch: 11, step: 3000 out of 5859, loss = 38602.69082050775...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3000\n",
            "\n",
            "running epoch: 11, step: 3075 out of 5859, loss = 38611.38104224236...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3100\n",
            "\n",
            "running epoch: 11, step: 3150 out of 5859, loss = 38610.612838682166...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3200\n",
            "\n",
            "running epoch: 11, step: 3225 out of 5859, loss = 38588.28027767553...\n",
            "\n",
            "running epoch: 11, step: 3300 out of 5859, loss = 38599.4081267987...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3300\n",
            "\n",
            "running epoch: 11, step: 3375 out of 5859, loss = 38590.08095633701...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3400\n",
            "\n",
            "running epoch: 11, step: 3450 out of 5859, loss = 38600.56519962511...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3500\n",
            "\n",
            "running epoch: 11, step: 3525 out of 5859, loss = 38592.973420660805...\n",
            "\n",
            "running epoch: 11, step: 3600 out of 5859, loss = 38600.47013416412...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3600\n",
            "\n",
            "running epoch: 11, step: 3675 out of 5859, loss = 38609.26783422028...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3700\n",
            "\n",
            "running epoch: 11, step: 3750 out of 5859, loss = 38606.42360682985...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3800\n",
            "\n",
            "running epoch: 11, step: 3825 out of 5859, loss = 38602.54776018525...\n",
            "\n",
            "running epoch: 11, step: 3900 out of 5859, loss = 38606.51254085491...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3900\n",
            "\n",
            "running epoch: 11, step: 3975 out of 5859, loss = 38610.767654756666...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4000\n",
            "\n",
            "running epoch: 11, step: 4050 out of 5859, loss = 38623.181198508086...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4100\n",
            "\n",
            "running epoch: 11, step: 4125 out of 5859, loss = 38624.868734473464...\n",
            "\n",
            "running epoch: 11, step: 4200 out of 5859, loss = 38616.508033801474...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4200\n",
            "\n",
            "running epoch: 11, step: 4275 out of 5859, loss = 38619.79966857168...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4300\n",
            "\n",
            "running epoch: 11, step: 4350 out of 5859, loss = 38609.59750093369...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4400\n",
            "\n",
            "running epoch: 11, step: 4425 out of 5859, loss = 38611.195251602745...\n",
            "\n",
            "running epoch: 11, step: 4500 out of 5859, loss = 38596.07404951678...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4500\n",
            "\n",
            "running epoch: 11, step: 4575 out of 5859, loss = 38587.534482729185...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4600\n",
            "\n",
            "running epoch: 11, step: 4650 out of 5859, loss = 38577.52431768706...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4700\n",
            "\n",
            "running epoch: 11, step: 4725 out of 5859, loss = 38574.39614549169...\n",
            "\n",
            "running epoch: 11, step: 4800 out of 5859, loss = 38582.55503654837...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4800\n",
            "\n",
            "running epoch: 11, step: 4875 out of 5859, loss = 38584.885778237796...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4900\n",
            "\n",
            "running epoch: 11, step: 4950 out of 5859, loss = 38582.49023476949...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5000\n",
            "\n",
            "running epoch: 11, step: 5025 out of 5859, loss = 38578.40676451204...\n",
            "\n",
            "running epoch: 11, step: 5100 out of 5859, loss = 38578.55366709652...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5100\n",
            "\n",
            "running epoch: 11, step: 5175 out of 5859, loss = 38571.800946148694...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5200\n",
            "\n",
            "running epoch: 11, step: 5250 out of 5859, loss = 38575.6075855343...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5300\n",
            "\n",
            "running epoch: 11, step: 5325 out of 5859, loss = 38574.67952431175...\n",
            "\n",
            "running epoch: 11, step: 5400 out of 5859, loss = 38566.71635931135...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5400\n",
            "\n",
            "running epoch: 11, step: 5475 out of 5859, loss = 38569.59363122888...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5500\n",
            "\n",
            "running epoch: 11, step: 5550 out of 5859, loss = 38568.07408610217...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5600\n",
            "\n",
            "running epoch: 11, step: 5625 out of 5859, loss = 38569.76131708529...\n",
            "\n",
            "running epoch: 11, step: 5700 out of 5859, loss = 38575.36999299739...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5700\n",
            "\n",
            "running epoch: 11, step: 5775 out of 5859, loss = 38577.37925893514...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5800\n",
            "\n",
            "running epoch: 11, step: 5850 out of 5859, loss = 38575.831610315014...\n",
            "\n",
            "running epoch: 12, step: 0 out of 5859, loss = 38007.0390625...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 0\n",
            "\n",
            "running epoch: 12, step: 75 out of 5859, loss = 38295.37243009869...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 100\n",
            "\n",
            "running epoch: 12, step: 150 out of 5859, loss = 38245.725967508275...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 200\n",
            "\n",
            "running epoch: 12, step: 225 out of 5859, loss = 38361.38088530144...\n",
            "\n",
            "running epoch: 12, step: 300 out of 5859, loss = 38374.26310086171...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 300\n",
            "\n",
            "running epoch: 12, step: 375 out of 5859, loss = 38558.79923848903...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 400\n",
            "\n",
            "running epoch: 12, step: 450 out of 5859, loss = 38475.39858041159...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 500\n",
            "\n",
            "running epoch: 12, step: 525 out of 5859, loss = 38542.87991251783...\n",
            "\n",
            "running epoch: 12, step: 600 out of 5859, loss = 38516.3422453463...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 600\n",
            "\n",
            "running epoch: 12, step: 675 out of 5859, loss = 38583.067420372594...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 700\n",
            "\n",
            "running epoch: 12, step: 750 out of 5859, loss = 38599.12363983439...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 800\n",
            "\n",
            "running epoch: 12, step: 825 out of 5859, loss = 38556.862408728055...\n",
            "\n",
            "running epoch: 12, step: 900 out of 5859, loss = 38587.04617915858...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 900\n",
            "\n",
            "running epoch: 12, step: 975 out of 5859, loss = 38583.88554807569...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1000\n",
            "\n",
            "running epoch: 12, step: 1050 out of 5859, loss = 38546.89621305602...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1100\n",
            "\n",
            "running epoch: 12, step: 1125 out of 5859, loss = 38555.88594686667...\n",
            "\n",
            "running epoch: 12, step: 1200 out of 5859, loss = 38562.11388458836...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1200\n",
            "\n",
            "running epoch: 12, step: 1275 out of 5859, loss = 38555.5848798124...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1300\n",
            "\n",
            "running epoch: 12, step: 1350 out of 5859, loss = 38567.089368118526...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1400\n",
            "\n",
            "running epoch: 12, step: 1425 out of 5859, loss = 38564.12403165542...\n",
            "\n",
            "running epoch: 12, step: 1500 out of 5859, loss = 38576.10233672344...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1500\n",
            "\n",
            "running epoch: 12, step: 1575 out of 5859, loss = 38611.805928031805...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1600\n",
            "\n",
            "running epoch: 12, step: 1650 out of 5859, loss = 38615.519054502955...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1700\n",
            "\n",
            "running epoch: 12, step: 1725 out of 5859, loss = 38617.07844071372...\n",
            "\n",
            "running epoch: 12, step: 1800 out of 5859, loss = 38624.701634942394...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1800\n",
            "\n",
            "running epoch: 12, step: 1875 out of 5859, loss = 38622.683539612204...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1900\n",
            "\n",
            "running epoch: 12, step: 1950 out of 5859, loss = 38616.120927569194...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2000\n",
            "\n",
            "running epoch: 12, step: 2025 out of 5859, loss = 38622.857281126606...\n",
            "\n",
            "running epoch: 12, step: 2100 out of 5859, loss = 38606.14796711387...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2100\n",
            "\n",
            "running epoch: 12, step: 2175 out of 5859, loss = 38601.854235480816...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2200\n",
            "\n",
            "running epoch: 12, step: 2250 out of 5859, loss = 38598.30489574078...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2300\n",
            "\n",
            "running epoch: 12, step: 2325 out of 5859, loss = 38620.72918066155...\n",
            "\n",
            "running epoch: 12, step: 2400 out of 5859, loss = 38607.264465001565...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2400\n",
            "\n",
            "running epoch: 12, step: 2475 out of 5859, loss = 38607.23580119144...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2500\n",
            "\n",
            "running epoch: 12, step: 2550 out of 5859, loss = 38599.23936538367...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2600\n",
            "\n",
            "running epoch: 12, step: 2625 out of 5859, loss = 38581.6307344226...\n",
            "\n",
            "running epoch: 12, step: 2700 out of 5859, loss = 38568.076917403276...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2700\n",
            "\n",
            "running epoch: 12, step: 2775 out of 5859, loss = 38595.811538916154...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2800\n",
            "\n",
            "running epoch: 12, step: 2850 out of 5859, loss = 38590.33958205454...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2900\n",
            "\n",
            "running epoch: 12, step: 2925 out of 5859, loss = 38600.662743506495...\n",
            "\n",
            "running epoch: 12, step: 3000 out of 5859, loss = 38601.24768957223...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3000\n",
            "\n",
            "running epoch: 12, step: 3075 out of 5859, loss = 38598.96326778893...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3100\n",
            "\n",
            "running epoch: 12, step: 3150 out of 5859, loss = 38602.59485827912...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3200\n",
            "\n",
            "running epoch: 12, step: 3225 out of 5859, loss = 38605.20100719738...\n",
            "\n",
            "running epoch: 12, step: 3300 out of 5859, loss = 38628.901542619664...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3300\n",
            "\n",
            "running epoch: 12, step: 3375 out of 5859, loss = 38634.08765805502...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3400\n",
            "\n",
            "running epoch: 12, step: 3450 out of 5859, loss = 38643.59206796943...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3500\n",
            "\n",
            "running epoch: 12, step: 3525 out of 5859, loss = 38646.47275817144...\n",
            "\n",
            "running epoch: 12, step: 3600 out of 5859, loss = 38651.62812630172...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3600\n",
            "\n",
            "running epoch: 12, step: 3675 out of 5859, loss = 38660.93517707766...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3700\n",
            "\n",
            "running epoch: 12, step: 3750 out of 5859, loss = 38662.14587464176...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3800\n",
            "\n",
            "running epoch: 12, step: 3825 out of 5859, loss = 38649.80295541607...\n",
            "\n",
            "running epoch: 12, step: 3900 out of 5859, loss = 38632.43069986061...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3900\n",
            "\n",
            "running epoch: 12, step: 3975 out of 5859, loss = 38628.01961770624...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4000\n",
            "\n",
            "running epoch: 12, step: 4050 out of 5859, loss = 38638.1016290345...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4100\n",
            "\n",
            "running epoch: 12, step: 4125 out of 5859, loss = 38633.53843765148...\n",
            "\n",
            "running epoch: 12, step: 4200 out of 5859, loss = 38629.08658466734...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4200\n",
            "\n",
            "running epoch: 12, step: 4275 out of 5859, loss = 38640.59464251783...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4300\n",
            "\n",
            "running epoch: 12, step: 4350 out of 5859, loss = 38640.53740160308...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4400\n",
            "\n",
            "running epoch: 12, step: 4425 out of 5859, loss = 38639.157210234975...\n",
            "\n",
            "running epoch: 12, step: 4500 out of 5859, loss = 38639.529873569765...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4500\n",
            "\n",
            "running epoch: 12, step: 4575 out of 5859, loss = 38631.70665820995...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4600\n",
            "\n",
            "running epoch: 12, step: 4650 out of 5859, loss = 38643.58323730784...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4700\n",
            "\n",
            "running epoch: 12, step: 4725 out of 5859, loss = 38642.56306039727...\n",
            "\n",
            "running epoch: 12, step: 4800 out of 5859, loss = 38638.90763073448...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4800\n",
            "\n",
            "running epoch: 12, step: 4875 out of 5859, loss = 38639.93662758281...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4900\n",
            "\n",
            "running epoch: 12, step: 4950 out of 5859, loss = 38631.46937645173...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5000\n",
            "\n",
            "running epoch: 12, step: 5025 out of 5859, loss = 38625.188712445284...\n",
            "\n",
            "running epoch: 12, step: 5100 out of 5859, loss = 38630.9084317107...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5100\n",
            "\n",
            "running epoch: 12, step: 5175 out of 5859, loss = 38628.01538274609...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5200\n",
            "\n",
            "running epoch: 12, step: 5250 out of 5859, loss = 38631.568335198055...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5300\n",
            "\n",
            "running epoch: 12, step: 5325 out of 5859, loss = 38635.8049654701...\n",
            "\n",
            "running epoch: 12, step: 5400 out of 5859, loss = 38633.98167440057...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5400\n",
            "\n",
            "running epoch: 12, step: 5475 out of 5859, loss = 38631.92774008172...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5500\n",
            "\n",
            "running epoch: 12, step: 5550 out of 5859, loss = 38630.70679199131...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5600\n",
            "\n",
            "running epoch: 12, step: 5625 out of 5859, loss = 38630.470033799545...\n",
            "\n",
            "running epoch: 12, step: 5700 out of 5859, loss = 38629.26465957179...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5700\n",
            "\n",
            "running epoch: 12, step: 5775 out of 5859, loss = 38626.61181708254...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5800\n",
            "\n",
            "running epoch: 12, step: 5850 out of 5859, loss = 38626.11431706385...\n",
            "\n",
            "running epoch: 13, step: 0 out of 5859, loss = 35988.7734375...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 0\n",
            "\n",
            "running epoch: 13, step: 75 out of 5859, loss = 38796.10870682566...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 100\n",
            "\n",
            "running epoch: 13, step: 150 out of 5859, loss = 39132.440837127484...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 200\n",
            "\n",
            "running epoch: 13, step: 225 out of 5859, loss = 39129.90784015487...\n",
            "\n",
            "running epoch: 13, step: 300 out of 5859, loss = 39000.80187136628...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 300\n",
            "\n",
            "running epoch: 13, step: 375 out of 5859, loss = 38836.41695063165...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 400\n",
            "\n",
            "running epoch: 13, step: 450 out of 5859, loss = 38819.20529898836...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 500\n",
            "\n",
            "running epoch: 13, step: 525 out of 5859, loss = 38835.202775962454...\n",
            "\n",
            "running epoch: 13, step: 600 out of 5859, loss = 38840.75755251664...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 600\n",
            "\n",
            "running epoch: 13, step: 675 out of 5859, loss = 38854.896617279956...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 700\n",
            "\n",
            "running epoch: 13, step: 750 out of 5859, loss = 38875.63275008322...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 800\n",
            "\n",
            "running epoch: 13, step: 825 out of 5859, loss = 38840.766864028454...\n",
            "\n",
            "running epoch: 13, step: 900 out of 5859, loss = 38809.71201702969...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 900\n",
            "\n",
            "running epoch: 13, step: 975 out of 5859, loss = 38799.58121878202...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1000\n",
            "\n",
            "running epoch: 13, step: 1050 out of 5859, loss = 38759.7012778009...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1100\n",
            "\n",
            "running epoch: 13, step: 1125 out of 5859, loss = 38709.64552342362...\n",
            "\n",
            "running epoch: 13, step: 1200 out of 5859, loss = 38663.97631205766...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1200\n",
            "\n",
            "running epoch: 13, step: 1275 out of 5859, loss = 38660.253759306426...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1300\n",
            "\n",
            "running epoch: 13, step: 1350 out of 5859, loss = 38639.02869691432...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1400\n",
            "\n",
            "running epoch: 13, step: 1425 out of 5859, loss = 38632.73390383941...\n",
            "\n",
            "running epoch: 13, step: 1500 out of 5859, loss = 38628.32258182045...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1500\n",
            "\n",
            "running epoch: 13, step: 1575 out of 5859, loss = 38622.25075348985...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1600\n",
            "\n",
            "running epoch: 13, step: 1650 out of 5859, loss = 38599.73386631208...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1700\n",
            "\n",
            "running epoch: 13, step: 1725 out of 5859, loss = 38585.94871406069...\n",
            "\n",
            "running epoch: 13, step: 1800 out of 5859, loss = 38561.8408089256...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1800\n",
            "\n",
            "running epoch: 13, step: 1875 out of 5859, loss = 38546.90302671908...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1900\n",
            "\n",
            "running epoch: 13, step: 1950 out of 5859, loss = 38513.4929743561...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2000\n",
            "\n",
            "running epoch: 13, step: 2025 out of 5859, loss = 38501.78287631879...\n",
            "\n",
            "running epoch: 13, step: 2100 out of 5859, loss = 38505.73340912809...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2100\n",
            "\n",
            "running epoch: 13, step: 2175 out of 5859, loss = 38537.005088357364...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2200\n",
            "\n",
            "running epoch: 13, step: 2250 out of 5859, loss = 38554.26221766021...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2300\n",
            "\n",
            "running epoch: 13, step: 2325 out of 5859, loss = 38557.96373619545...\n",
            "\n",
            "running epoch: 13, step: 2400 out of 5859, loss = 38581.759318220276...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2400\n",
            "\n",
            "running epoch: 13, step: 2475 out of 5859, loss = 38568.814786797004...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2500\n",
            "\n",
            "running epoch: 13, step: 2550 out of 5859, loss = 38568.741848325415...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2600\n",
            "\n",
            "running epoch: 13, step: 2625 out of 5859, loss = 38553.40919753784...\n",
            "\n",
            "running epoch: 13, step: 2700 out of 5859, loss = 38540.80011092535...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2700\n",
            "\n",
            "running epoch: 13, step: 2775 out of 5859, loss = 38544.33227116917...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2800\n",
            "\n",
            "running epoch: 13, step: 2850 out of 5859, loss = 38557.12830818682...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2900\n",
            "\n",
            "running epoch: 13, step: 2925 out of 5859, loss = 38572.32745015059...\n",
            "\n",
            "running epoch: 13, step: 3000 out of 5859, loss = 38562.67935362692...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3000\n",
            "\n",
            "running epoch: 13, step: 3075 out of 5859, loss = 38588.11281074752...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3100\n",
            "\n",
            "running epoch: 13, step: 3150 out of 5859, loss = 38595.68073317498...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3200\n",
            "\n",
            "running epoch: 13, step: 3225 out of 5859, loss = 38594.891068781966...\n",
            "\n",
            "running epoch: 13, step: 3300 out of 5859, loss = 38577.179227767156...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3300\n",
            "\n",
            "running epoch: 13, step: 3375 out of 5859, loss = 38577.379236591936...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3400\n",
            "\n",
            "running epoch: 13, step: 3450 out of 5859, loss = 38575.734102773655...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3500\n",
            "\n",
            "running epoch: 13, step: 3525 out of 5859, loss = 38585.7646484375...\n",
            "\n",
            "running epoch: 13, step: 3600 out of 5859, loss = 38589.86043102176...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3600\n",
            "\n",
            "running epoch: 13, step: 3675 out of 5859, loss = 38586.909861368506...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3700\n",
            "\n",
            "running epoch: 13, step: 3750 out of 5859, loss = 38580.03519738487...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3800\n",
            "\n",
            "running epoch: 13, step: 3825 out of 5859, loss = 38591.380588306165...\n",
            "\n",
            "running epoch: 13, step: 3900 out of 5859, loss = 38590.09901457559...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3900\n",
            "\n",
            "running epoch: 13, step: 3975 out of 5859, loss = 38583.431114519146...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4000\n",
            "\n",
            "running epoch: 13, step: 4050 out of 5859, loss = 38583.59725752515...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4100\n",
            "\n",
            "running epoch: 13, step: 4125 out of 5859, loss = 38582.527618778025...\n",
            "\n",
            "running epoch: 13, step: 4200 out of 5859, loss = 38588.732061097806...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4200\n",
            "\n",
            "running epoch: 13, step: 4275 out of 5859, loss = 38592.861575234594...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4300\n",
            "\n",
            "running epoch: 13, step: 4350 out of 5859, loss = 38588.08425730076...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4400\n",
            "\n",
            "running epoch: 13, step: 4425 out of 5859, loss = 38588.269628773865...\n",
            "\n",
            "running epoch: 13, step: 4500 out of 5859, loss = 38584.88644927863...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4500\n",
            "\n",
            "running epoch: 13, step: 4575 out of 5859, loss = 38588.983275940365...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4600\n",
            "\n",
            "running epoch: 13, step: 4650 out of 5859, loss = 38585.67956361871...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4700\n",
            "\n",
            "running epoch: 13, step: 4725 out of 5859, loss = 38574.7088260917...\n",
            "\n",
            "running epoch: 13, step: 4800 out of 5859, loss = 38578.77679251393...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4800\n",
            "\n",
            "running epoch: 13, step: 4875 out of 5859, loss = 38571.71772897547...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4900\n",
            "\n",
            "running epoch: 13, step: 4950 out of 5859, loss = 38571.413352021686...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5000\n",
            "\n",
            "running epoch: 13, step: 5025 out of 5859, loss = 38563.5920071099...\n",
            "\n",
            "running epoch: 13, step: 5100 out of 5859, loss = 38569.14669573062...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5100\n",
            "\n",
            "running epoch: 13, step: 5175 out of 5859, loss = 38575.49308746196...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5200\n",
            "\n",
            "running epoch: 13, step: 5250 out of 5859, loss = 38581.73109995417...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5300\n",
            "\n",
            "running epoch: 13, step: 5325 out of 5859, loss = 38589.18719525969...\n",
            "\n",
            "running epoch: 13, step: 5400 out of 5859, loss = 38589.797613795476...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5400\n",
            "\n",
            "running epoch: 13, step: 5475 out of 5859, loss = 38583.31507622752...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5500\n",
            "\n",
            "running epoch: 13, step: 5550 out of 5859, loss = 38582.42917626047...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5600\n",
            "\n",
            "running epoch: 13, step: 5625 out of 5859, loss = 38588.53373323909...\n",
            "\n",
            "running epoch: 13, step: 5700 out of 5859, loss = 38585.98510369617...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5700\n",
            "\n",
            "running epoch: 13, step: 5775 out of 5859, loss = 38589.89567587052...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5800\n",
            "\n",
            "running epoch: 13, step: 5850 out of 5859, loss = 38591.822982649865...\n",
            "\n",
            "running epoch: 14, step: 0 out of 5859, loss = 38942.0390625...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 0\n",
            "\n",
            "running epoch: 14, step: 75 out of 5859, loss = 38512.04728618421...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 100\n",
            "\n",
            "running epoch: 14, step: 150 out of 5859, loss = 38722.603088783115...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 200\n",
            "\n",
            "running epoch: 14, step: 225 out of 5859, loss = 38741.57822870575...\n",
            "\n",
            "running epoch: 14, step: 300 out of 5859, loss = 38571.00804609634...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 300\n",
            "\n",
            "running epoch: 14, step: 375 out of 5859, loss = 38794.76795212766...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 400\n",
            "\n",
            "running epoch: 14, step: 450 out of 5859, loss = 38593.606170315965...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 500\n",
            "\n",
            "running epoch: 14, step: 525 out of 5859, loss = 38488.14634327471...\n",
            "\n",
            "running epoch: 14, step: 600 out of 5859, loss = 38490.16401050333...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 600\n",
            "\n",
            "running epoch: 14, step: 675 out of 5859, loss = 38489.83630732248...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 700\n",
            "\n",
            "running epoch: 14, step: 750 out of 5859, loss = 38506.284225199735...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 800\n",
            "\n",
            "running epoch: 14, step: 825 out of 5859, loss = 38528.45851146338...\n",
            "\n",
            "running epoch: 14, step: 900 out of 5859, loss = 38506.099416447...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 900\n",
            "\n",
            "running epoch: 14, step: 975 out of 5859, loss = 38550.23158139088...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1000\n",
            "\n",
            "running epoch: 14, step: 1050 out of 5859, loss = 38544.202954031876...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1100\n",
            "\n",
            "running epoch: 14, step: 1125 out of 5859, loss = 38529.76661717362...\n",
            "\n",
            "running epoch: 14, step: 1200 out of 5859, loss = 38486.679014232934...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1200\n",
            "\n",
            "running epoch: 14, step: 1275 out of 5859, loss = 38467.73485562794...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1300\n",
            "\n",
            "running epoch: 14, step: 1350 out of 5859, loss = 38466.961744194115...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1400\n",
            "\n",
            "running epoch: 14, step: 1425 out of 5859, loss = 38465.93037780505...\n",
            "\n",
            "running epoch: 14, step: 1500 out of 5859, loss = 38453.544225724516...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1500\n",
            "\n",
            "running epoch: 14, step: 1575 out of 5859, loss = 38449.80211472874...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1600\n",
            "\n",
            "running epoch: 14, step: 1650 out of 5859, loss = 38445.61931689128...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1700\n",
            "\n",
            "running epoch: 14, step: 1725 out of 5859, loss = 38429.535959679175...\n",
            "\n",
            "running epoch: 14, step: 1800 out of 5859, loss = 38427.224632148806...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1800\n",
            "\n",
            "running epoch: 14, step: 1875 out of 5859, loss = 38425.36769139792...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1900\n",
            "\n",
            "running epoch: 14, step: 1950 out of 5859, loss = 38425.69121604306...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2000\n",
            "\n",
            "running epoch: 14, step: 2025 out of 5859, loss = 38455.13661849087...\n",
            "\n",
            "running epoch: 14, step: 2100 out of 5859, loss = 38449.27504945562...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2100\n",
            "\n",
            "running epoch: 14, step: 2175 out of 5859, loss = 38448.426034366385...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2200\n",
            "\n",
            "running epoch: 14, step: 2250 out of 5859, loss = 38449.2231525572...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2300\n",
            "\n",
            "running epoch: 14, step: 2325 out of 5859, loss = 38443.31861296217...\n",
            "\n",
            "running epoch: 14, step: 2400 out of 5859, loss = 38466.57742379477...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2400\n",
            "\n",
            "running epoch: 14, step: 2475 out of 5859, loss = 38498.91254322748...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2500\n",
            "\n",
            "running epoch: 14, step: 2550 out of 5859, loss = 38489.1154311422...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2600\n",
            "\n",
            "running epoch: 14, step: 2625 out of 5859, loss = 38489.38105572877...\n",
            "\n",
            "running epoch: 14, step: 2700 out of 5859, loss = 38508.419744712606...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2700\n",
            "\n",
            "running epoch: 14, step: 2775 out of 5859, loss = 38504.31179923901...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2800\n",
            "\n",
            "running epoch: 14, step: 2850 out of 5859, loss = 38492.36516792353...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2900\n",
            "\n",
            "running epoch: 14, step: 2925 out of 5859, loss = 38481.0520415029...\n",
            "\n",
            "running epoch: 14, step: 3000 out of 5859, loss = 38483.939146586556...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3000\n",
            "\n",
            "running epoch: 14, step: 3075 out of 5859, loss = 38477.08579019018...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3100\n",
            "\n",
            "running epoch: 14, step: 3150 out of 5859, loss = 38481.22691457077...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3200\n",
            "\n",
            "running epoch: 14, step: 3225 out of 5859, loss = 38479.409717916926...\n",
            "\n",
            "running epoch: 14, step: 3300 out of 5859, loss = 38480.59796155521...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3300\n",
            "\n",
            "running epoch: 14, step: 3375 out of 5859, loss = 38477.978380248445...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3400\n",
            "\n",
            "running epoch: 14, step: 3450 out of 5859, loss = 38473.64293637714...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3500\n",
            "\n",
            "running epoch: 14, step: 3525 out of 5859, loss = 38474.97686272511...\n",
            "\n",
            "running epoch: 14, step: 3600 out of 5859, loss = 38467.39450521557...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3600\n",
            "\n",
            "running epoch: 14, step: 3675 out of 5859, loss = 38471.52598251326...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3700\n",
            "\n",
            "running epoch: 14, step: 3750 out of 5859, loss = 38473.933073055516...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3800\n",
            "\n",
            "running epoch: 14, step: 3825 out of 5859, loss = 38473.57551640911...\n",
            "\n",
            "running epoch: 14, step: 3900 out of 5859, loss = 38482.79096105165...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3900\n",
            "\n",
            "running epoch: 14, step: 3975 out of 5859, loss = 38487.014203384366...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4000\n",
            "\n",
            "running epoch: 14, step: 4050 out of 5859, loss = 38501.17910315354...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4100\n",
            "\n",
            "running epoch: 14, step: 4125 out of 5859, loss = 38492.40507225521...\n",
            "\n",
            "running epoch: 14, step: 4200 out of 5859, loss = 38501.71432583016...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4200\n",
            "\n",
            "running epoch: 14, step: 4275 out of 5859, loss = 38508.729805527946...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4300\n",
            "\n",
            "running epoch: 14, step: 4350 out of 5859, loss = 38508.01698693547...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4400\n",
            "\n",
            "running epoch: 14, step: 4425 out of 5859, loss = 38504.616566171484...\n",
            "\n",
            "running epoch: 14, step: 4500 out of 5859, loss = 38505.97589337786...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4500\n",
            "\n",
            "running epoch: 14, step: 4575 out of 5859, loss = 38502.69940057501...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4600\n",
            "\n",
            "running epoch: 14, step: 4650 out of 5859, loss = 38489.525524584766...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4700\n",
            "\n",
            "running epoch: 14, step: 4725 out of 5859, loss = 38478.4493964571...\n",
            "\n",
            "running epoch: 14, step: 4800 out of 5859, loss = 38477.49901306369...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4800\n",
            "\n",
            "running epoch: 14, step: 4875 out of 5859, loss = 38467.222705919296...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 4900\n",
            "\n",
            "running epoch: 14, step: 4950 out of 5859, loss = 38461.79438339477...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5000\n",
            "\n",
            "running epoch: 14, step: 5025 out of 5859, loss = 38467.074364087995...\n",
            "\n",
            "running epoch: 14, step: 5100 out of 5859, loss = 38478.07210749118...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5100\n",
            "\n",
            "running epoch: 14, step: 5175 out of 5859, loss = 38485.90866952038...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5200\n",
            "\n",
            "running epoch: 14, step: 5250 out of 5859, loss = 38482.52473412803...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5300\n",
            "\n",
            "running epoch: 14, step: 5325 out of 5859, loss = 38491.09057571348...\n",
            "\n",
            "running epoch: 14, step: 5400 out of 5859, loss = 38488.16381804296...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5400\n",
            "\n",
            "running epoch: 14, step: 5475 out of 5859, loss = 38486.3960727778...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5500\n",
            "\n",
            "running epoch: 14, step: 5550 out of 5859, loss = 38493.720196107686...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5600\n",
            "\n",
            "running epoch: 14, step: 5625 out of 5859, loss = 38488.05336273551...\n",
            "\n",
            "running epoch: 14, step: 5700 out of 5859, loss = 38495.99132827574...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5700\n",
            "\n",
            "running epoch: 14, step: 5775 out of 5859, loss = 38495.17923506211...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 5800\n",
            "\n",
            "running epoch: 14, step: 5850 out of 5859, loss = 38506.13701584131...\n",
            "\n",
            "running epoch: 15, step: 0 out of 5859, loss = 45631.2265625...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 0\n",
            "\n",
            "running epoch: 15, step: 75 out of 5859, loss = 38605.84123149671...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 100\n",
            "\n",
            "running epoch: 15, step: 150 out of 5859, loss = 38669.952581746686...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 200\n",
            "\n",
            "running epoch: 15, step: 225 out of 5859, loss = 38740.17892699115...\n",
            "\n",
            "running epoch: 15, step: 300 out of 5859, loss = 38687.30255917774...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 300\n",
            "\n",
            "running epoch: 15, step: 375 out of 5859, loss = 38860.44934341755...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 400\n",
            "\n",
            "running epoch: 15, step: 450 out of 5859, loss = 38721.21068199141...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 500\n",
            "\n",
            "running epoch: 15, step: 525 out of 5859, loss = 38651.47084051212...\n",
            "\n",
            "running epoch: 15, step: 600 out of 5859, loss = 38627.56850236585...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 600\n",
            "\n",
            "running epoch: 15, step: 675 out of 5859, loss = 38631.98093969582...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 700\n",
            "\n",
            "running epoch: 15, step: 750 out of 5859, loss = 38642.38512452147...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 800\n",
            "\n",
            "running epoch: 15, step: 825 out of 5859, loss = 38614.9647704487...\n",
            "\n",
            "running epoch: 15, step: 900 out of 5859, loss = 38640.43236031146...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 900\n",
            "\n",
            "running epoch: 15, step: 975 out of 5859, loss = 38615.333197922...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1000\n",
            "\n",
            "running epoch: 15, step: 1050 out of 5859, loss = 38612.17300301796...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1100\n",
            "\n",
            "running epoch: 15, step: 1125 out of 5859, loss = 38615.69117208315...\n",
            "\n",
            "running epoch: 15, step: 1200 out of 5859, loss = 38616.54688963624...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1200\n",
            "\n",
            "running epoch: 15, step: 1275 out of 5859, loss = 38618.32481723893...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1300\n",
            "\n",
            "running epoch: 15, step: 1350 out of 5859, loss = 38622.22245819069...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1400\n",
            "\n",
            "running epoch: 15, step: 1425 out of 5859, loss = 38615.600435275686...\n",
            "\n",
            "running epoch: 15, step: 1500 out of 5859, loss = 38606.466450751584...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1500\n",
            "\n",
            "running epoch: 15, step: 1575 out of 5859, loss = 38601.951515159024...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1600\n",
            "\n",
            "running epoch: 15, step: 1650 out of 5859, loss = 38579.32196751022...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1700\n",
            "\n",
            "running epoch: 15, step: 1725 out of 5859, loss = 38588.825776949954...\n",
            "\n",
            "running epoch: 15, step: 1800 out of 5859, loss = 38619.56333395509...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1800\n",
            "\n",
            "running epoch: 15, step: 1875 out of 5859, loss = 38608.08215097781...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 1900\n",
            "\n",
            "running epoch: 15, step: 1950 out of 5859, loss = 38599.420188164724...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2000\n",
            "\n",
            "running epoch: 15, step: 2025 out of 5859, loss = 38593.56997412543...\n",
            "\n",
            "running epoch: 15, step: 2100 out of 5859, loss = 38597.28735386423...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2100\n",
            "\n",
            "running epoch: 15, step: 2175 out of 5859, loss = 38605.90058270623...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2200\n",
            "\n",
            "running epoch: 15, step: 2250 out of 5859, loss = 38623.83971012883...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2300\n",
            "\n",
            "running epoch: 15, step: 2325 out of 5859, loss = 38657.27406894884...\n",
            "\n",
            "running epoch: 15, step: 2400 out of 5859, loss = 38643.92936048782...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2400\n",
            "\n",
            "running epoch: 15, step: 2475 out of 5859, loss = 38632.57186490307...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2500\n",
            "\n",
            "running epoch: 15, step: 2550 out of 5859, loss = 38619.85105871472...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2600\n",
            "\n",
            "running epoch: 15, step: 2625 out of 5859, loss = 38610.900261210016...\n",
            "\n",
            "running epoch: 15, step: 2700 out of 5859, loss = 38622.114490292945...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2700\n",
            "\n",
            "running epoch: 15, step: 2775 out of 5859, loss = 38628.70124082538...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2800\n",
            "\n",
            "running epoch: 15, step: 2850 out of 5859, loss = 38627.663676122414...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 2900\n",
            "\n",
            "running epoch: 15, step: 2925 out of 5859, loss = 38618.41081374423...\n",
            "\n",
            "running epoch: 15, step: 3000 out of 5859, loss = 38602.923949178396...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3000\n",
            "\n",
            "running epoch: 15, step: 3075 out of 5859, loss = 38590.5486674811...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3100\n",
            "\n",
            "running epoch: 15, step: 3150 out of 5859, loss = 38590.40720641761...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3200\n",
            "\n",
            "running epoch: 15, step: 3225 out of 5859, loss = 38579.561611830635...\n",
            "\n",
            "running epoch: 15, step: 3300 out of 5859, loss = 38588.710406765946...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3300\n",
            "\n",
            "running epoch: 15, step: 3375 out of 5859, loss = 38580.898659077866...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3400\n",
            "\n",
            "running epoch: 15, step: 3450 out of 5859, loss = 38577.828162919264...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3500\n",
            "\n",
            "running epoch: 15, step: 3525 out of 5859, loss = 38568.66473994523...\n",
            "\n",
            "running epoch: 15, step: 3600 out of 5859, loss = 38579.10836345373...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3600\n",
            "\n",
            "running epoch: 15, step: 3675 out of 5859, loss = 38576.83813343733...\n",
            "\n",
            "Losses saved to ./logs/batch_transpose_losses_history... | at step 3700\n",
            "\n",
            "running epoch: 15, step: 3750 out of 5859, loss = 38583.58074148977...\n",
            "\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rT_8veJkK_Dn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"plotting the vectors using TSNE\"\"\"\n",
        "def plot_words(indixes, embeddings):\n",
        "    \"\"\"embeddings of shape num_values * embed_dimenssion\"\"\"\n",
        "    tsne = TSNE(n_components=2, init=\"pca\", n_iter=1000)\n",
        "    transformed = tsne.fit_transform(embeddings)\n",
        "    print('TSNE calculated...')\n",
        "    \n",
        "    plt.figure(figsize=(15, 15))\n",
        "    words = [batcher.index2word[index] for index in indixes]\n",
        "    for i, word in enumerate(words):\n",
        "        x, y = transformed[i, :]\n",
        "        plt.scatter(x, y)\n",
        "        plt.annotate(word, xy=(x, y), xytext=(5, 2), textcoords=\"offset points\", ha=\"right\", va=\"bottom\")\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DgqYK2aNK_Uf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"function to map token to corresponding word vector\"\"\"\n",
        "embeddings = model.get_vectors_from_words(batcher, ['anarchism', 'UNK'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s-Aqugz8K_nP",
        "colab_type": "code",
        "outputId": "3879b92f-67b0-45d5-8e32-f2ebf6409449",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 897
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\"plotting the embeddings\"\"\"\n",
        "indices = np.arange(batcher.vocab_size)\n",
        "np.random.shuffle(indices)\n",
        "indices = indices[:200]\n",
        "embed_from_indices = model.get_vectors_from_indexes(batcher, indices)\n",
        "print(embed_from_indices.shape)\n",
        "\n",
        "plot_words(indices, embed_from_indices)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(200, 300)\n",
            "TSNE calculated...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA24AAANOCAYAAABp/V9RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 1080x1080 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "3v9G0TmuLCVr",
        "colab_type": "code",
        "outputId": "77d19490-2b07-4a92-a2ea-4d3772c1ac88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\"plot loss without tensorboard\"\"\"\n",
        "losses = np.load(\"./logs/\" + model_name + \"losses_history.npy\")\n",
        "plt.xlabel('step')\n",
        "plt.ylabel('loss')\n",
        "plt.plot(losses)\n",
        "plt.show()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAFYCAYAAADOev/+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "IYRmsbLxCLRC",
        "colab_type": "code",
        "outputId": "32ffa002-e9ff-4a94-bd60-c55d1d974c4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        }
      },
      "cell_type": "code",
      "source": [
        "epoch_losses = np.load(\"./logs/\" + model_name + \"epoch_losses.npy\")\n",
        "plt.plot(epoch_losses)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf0AAAFYCAYAAABZHSXVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "V_LwnFh3VR4_",
        "colab_type": "code",
        "outputId": "e176429f-2c04-43c9-9a9f-ecf02aed05f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(batcher.vocab_size)\n",
        "embeddings = model.get_vectors_from_indexes(batcher, range(batcher.vocab_size))"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16525\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tu8VIaPgVSOu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"nearest neighbors, word analogies using gensim\"\"\"\n",
        "def create_file_for_gensim(embeddings, vocab_size, vec_size, filename):\n",
        "    with open(filename, 'w') as f:\n",
        "        f.write(str(vocab_size) + ' ' + str(vec_size) + '\\n')\n",
        "        for i in range(vocab_size):\n",
        "            to_write = ' '.join([batcher.index2word[i]] + [str(num) for num in embeddings[i]])\n",
        "            f.write(to_write + '\\n')\n",
        "\n",
        "create_file_for_gensim(embeddings, embeddings.shape[0], EMBEDDINGS_SIZE, 'word2vec.vec')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TEY4PBldVSgA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "w2v = KeyedVectors.load_word2vec_format('word2vec.vec', binary=False)\n",
        "\n",
        "def print_similar(similar_to):\n",
        "  for similar in w2v.similar_by_word(similar_to)[:20]:\n",
        "      print(\"word: {0}, similarity: {1:.2f}\".format(similar[0], similar[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3MBDg-6nVl-_",
        "colab_type": "code",
        "outputId": "0baac3e6-ccbe-4bca-f499-c7ab7ff9f0c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "cell_type": "code",
      "source": [
        "print_similar('moscow')"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word: solomon, similarity: 1.00\n",
            "word: queensland, similarity: 1.00\n",
            "word: portugal, similarity: 1.00\n",
            "word: olaf, similarity: 1.00\n",
            "word: kabul, similarity: 0.99\n",
            "word: hungarian, similarity: 0.99\n",
            "word: encyclopaedia, similarity: 0.99\n",
            "word: festivals, similarity: 0.99\n",
            "word: leningrad, similarity: 0.99\n",
            "word: latvia, similarity: 0.99\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "3LYfUvv4Vt-Q",
        "colab_type": "code",
        "outputId": "2eb19b6f-a767-49ac-d1c3-b2eb60ca4ce3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "cell_type": "code",
      "source": [
        "print_similar('king')"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word: president, similarity: 1.00\n",
            "word: pennsylvania, similarity: 1.00\n",
            "word: sultan, similarity: 1.00\n",
            "word: venice, similarity: 1.00\n",
            "word: walton, similarity: 1.00\n",
            "word: maryland, similarity: 1.00\n",
            "word: iliad, similarity: 1.00\n",
            "word: florida, similarity: 1.00\n",
            "word: filipino, similarity: 1.00\n",
            "word: rutgers, similarity: 1.00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "s-6j_Zv-VuP3",
        "colab_type": "code",
        "outputId": "78891b7e-fa25-42a7-8291-ad682b7d106a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\"here high is an antonymous\"\"\"\n",
        "similar_words = w2v.most_similar(positive=['white', 'small'], negative=['black'])\n",
        "for similar in similar_words:\n",
        "    print(\"word: {0}, similarity: {1:.2f}\".format(similar[0], similar[1]))"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word: nitrogen, similarity: 1.00\n",
            "word: disease, similarity: 1.00\n",
            "word: surgical, similarity: 0.99\n",
            "word: alcohol, similarity: 0.99\n",
            "word: salts, similarity: 0.99\n",
            "word: resistivity, similarity: 0.99\n",
            "word: ornamental, similarity: 0.99\n",
            "word: high, similarity: 0.99\n",
            "word: compounds, similarity: 0.99\n",
            "word: organ, similarity: 0.99\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "3dyIgsJx44lf",
        "colab_type": "code",
        "outputId": "ee00e418-15dc-46f3-a97a-f04cf06cb4b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\"princess is close to queen\"\"\"\n",
        "similar_words = w2v.most_similar(positive=['king', 'woman'], negative=['man'])\n",
        "for similar in similar_words:\n",
        "    print(\"word: {0}, similarity: {1:.2f}\".format(similar[0], similar[1]))"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word: babylon, similarity: 1.00\n",
            "word: saint, similarity: 1.00\n",
            "word: hungary, similarity: 0.99\n",
            "word: multiplied, similarity: 0.99\n",
            "word: amp, similarity: 0.99\n",
            "word: judas, similarity: 0.99\n",
            "word: albert, similarity: 0.99\n",
            "word: roy, similarity: 0.99\n",
            "word: princess, similarity: 0.99\n",
            "word: bulgaria, similarity: 0.99\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "O31rP_sCVugD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"nearest neighbors, word analogies using my own implemetation\"\"\"\n",
        "\"\"\"as it can be seen we got the same results!!!!!!!!!\"\"\"\n",
        "\"\"\"as we see one matrix model is good for word analogies, but not for nearest neighbours\"\"\"\n",
        "def get_similar_by_word(embeddings, similar_to, num_top=10):\n",
        "    index = batcher.word2index[similar_to]\n",
        "    with tf.device(device):\n",
        "        embed = tf.placeholder(dtype=tf.float32, shape=(embeddings.shape[0], embeddings.shape[1]), name='embeddings')\n",
        "        norm_embed = tf.nn.l2_normalize(embed, 1)\n",
        "        nearby_index = tf.placeholder(tf.int32, shape=(), name='nearby_index')\n",
        "        nearby_embed = tf.gather(norm_embed, nearby_index)\n",
        "        nearby_embed = tf.reshape(nearby_embed, (1, -1))\n",
        "        nearby_dist = tf.matmul(nearby_embed, norm_embed, transpose_b=True)\n",
        "        nearby_val, nearby_idx = tf.nn.top_k(nearby_dist, min(num_top, embeddings.shape[0]))\n",
        "        \n",
        "        feed_dict = {embed : embeddings, nearby_index : index}\n",
        "        vals, idxs = model.sess.run([nearby_val, nearby_idx], feed_dict=feed_dict)\n",
        "        words = np.array([batcher.index2word[idx] for idx in idxs.flatten()])\n",
        "        return vals.flatten()[1:], words[1:]\n",
        "      \n",
        "def get_analogy_by_word(embeddings, positive, negative, num_top=10):\n",
        "    a = batcher.word2index[negative[0]]\n",
        "    b = batcher.word2index[positive[0]]\n",
        "    c = batcher.word2index[positive[1]]\n",
        "    with tf.device(device):\n",
        "        embed = tf.placeholder(dtype=tf.float32, shape=(embeddings.shape[0], embeddings.shape[1]), name='embeddings')\n",
        "        norm_embed = tf.nn.l2_normalize(embed, 1)\n",
        "        a_index = tf.placeholder(tf.int32, shape=(), name='a_index')\n",
        "        b_index = tf.placeholder(tf.int32, shape=(), name='b_index')\n",
        "        c_index = tf.placeholder(tf.int32, shape=(), name='c_index')\n",
        "        a_embed = tf.reshape(tf.gather(norm_embed, a_index), (1, -1))\n",
        "        b_embed = tf.reshape(tf.gather(norm_embed, b_index), (1, -1))\n",
        "        c_embed = tf.reshape(tf.gather(norm_embed, c_index), (1, -1))\n",
        "        target_embed = c_embed + b_embed - a_embed\n",
        "        target_dist = tf.matmul(target_embed, norm_embed, transpose_b=True)\n",
        "        target_val, target_idx = tf.nn.top_k(target_dist, min(num_top, embeddings.shape[0]))\n",
        "        \n",
        "        feed_dict = {embed : embeddings, a_index : a, b_index : b, c_index : c}\n",
        "        vals, idxs = model.sess.run([target_val, target_idx], feed_dict=feed_dict)\n",
        "        words = np.array([batcher.index2word[idx] for idx in idxs.flatten()])\n",
        "        return vals.flatten(), words\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "by9rUrC0VvLt",
        "colab_type": "code",
        "outputId": "74b1928b-af5a-4c03-b3a0-cf84bd846343",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "vals, words = get_similar_by_word(embeddings, 'movie')\n",
        "for val, word in zip(vals, words):\n",
        "    print(\"word: {0}, similarity: {1:.2f}\".format(word, val))"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word: film, similarity: 1.00\n",
            "word: xbox, similarity: 1.00\n",
            "word: agatha, similarity: 1.00\n",
            "word: sharon, similarity: 1.00\n",
            "word: ang, similarity: 1.00\n",
            "word: circa, similarity: 1.00\n",
            "word: appearing, similarity: 1.00\n",
            "word: cub, similarity: 1.00\n",
            "word: titled, similarity: 1.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HlvUr3O7WHGj",
        "colab_type": "code",
        "outputId": "5f064e9c-0c08-45e2-b3f4-23ec616a847f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "vals, words = get_similar_by_word(embeddings, 'china')\n",
        "for val, word in zip(vals, words):\n",
        "    print(\"word: {0}, similarity: {1:.2f}\".format(word, val))"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word: canada, similarity: 1.00\n",
            "word: kuwait, similarity: 1.00\n",
            "word: turkish, similarity: 1.00\n",
            "word: sadr, similarity: 1.00\n",
            "word: latvia, similarity: 1.00\n",
            "word: browne, similarity: 1.00\n",
            "word: bangladesh, similarity: 0.99\n",
            "word: russia, similarity: 0.99\n",
            "word: bavaria, similarity: 0.99\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qLKizXKywaqi",
        "colab_type": "code",
        "outputId": "26ce9c95-f31f-4bdf-a6ed-540c1fa6885e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "vals, words = get_similar_by_word(embeddings, 'apple')\n",
        "for val, word in zip(vals, words):\n",
        "    print(\"word: {0}, similarity: {1:.2f}\".format(word, val))"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word: microsoft, similarity: 0.99\n",
            "word: dom, similarity: 0.98\n",
            "word: cd, similarity: 0.98\n",
            "word: ibm, similarity: 0.98\n",
            "word: fm, similarity: 0.98\n",
            "word: imac, similarity: 0.97\n",
            "word: omega, similarity: 0.97\n",
            "word: bose, similarity: 0.97\n",
            "word: pi, similarity: 0.97\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Gt7ldlhQwdYH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "a85e6a9e-e67d-4f78-d17d-766444b4ebe1"
      },
      "cell_type": "code",
      "source": [
        "vals, words = get_similar_by_word(embeddings, 'usa')\n",
        "for val, word in zip(vals, words):\n",
        "    print(\"word: {0}, similarity: {1:.2f}\".format(word, val))"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word: ghana, similarity: 1.00\n",
            "word: boulevard, similarity: 1.00\n",
            "word: hall, similarity: 1.00\n",
            "word: park, similarity: 1.00\n",
            "word: saskatchewan, similarity: 1.00\n",
            "word: belgium, similarity: 1.00\n",
            "word: maldives, similarity: 1.00\n",
            "word: ames, similarity: 1.00\n",
            "word: normandy, similarity: 1.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qqnPgED-WHVb",
        "colab_type": "code",
        "outputId": "b9afebeb-4e83-45fc-92b8-627a762b11ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "vals, words = get_analogy_by_word(embeddings, positive=['white', 'small'], negative=['black'])\n",
        "for val, word in zip(vals, words):\n",
        "    print(\"word: {0}, similarity: {1:.2f}\".format(word, val))"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word: nitrogen, similarity: 1.45\n",
            "word: disease, similarity: 1.45\n",
            "word: surgical, similarity: 1.45\n",
            "word: alcohol, similarity: 1.45\n",
            "word: salts, similarity: 1.45\n",
            "word: resistivity, similarity: 1.45\n",
            "word: ornamental, similarity: 1.45\n",
            "word: high, similarity: 1.45\n",
            "word: compounds, similarity: 1.45\n",
            "word: organ, similarity: 1.45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ywAZcJeQyaJG",
        "colab_type": "code",
        "outputId": "b71fcded-205e-42ad-f94a-69d3a62fe910",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "vals, words = get_analogy_by_word(embeddings, positive=['woman', 'king'], negative=['man'])\n",
        "for val, word in zip(vals, words):\n",
        "    print(\"word: {0}, similarity: {1:.2f}\".format(word, val))"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word: babylon, similarity: 1.39\n",
            "word: saint, similarity: 1.39\n",
            "word: hungary, similarity: 1.39\n",
            "word: multiplied, similarity: 1.39\n",
            "word: amp, similarity: 1.39\n",
            "word: judas, similarity: 1.39\n",
            "word: albert, similarity: 1.39\n",
            "word: roy, similarity: 1.39\n",
            "word: princess, similarity: 1.39\n",
            "word: bulgaria, similarity: 1.39\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QFH3oKl5WdGG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.save(\"./logs/\" + model_name + \"embeddings\", embeddings)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "amY5FPK2WHkM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"download graph and loss to visualize them localy (ngrock is too slow with VPN) \"\"\"\n",
        "from google.colab import files\n",
        "files.download(\"./logs/\" + model_name + \"embeddings.npy\") "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PEfZIgBsWIEF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"model destructor (closses tf.Session())\"\"\"\n",
        "model.close()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}